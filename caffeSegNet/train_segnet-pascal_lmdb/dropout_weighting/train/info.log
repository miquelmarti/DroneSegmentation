I0418 18:16:57.570538 24121 caffe.cpp:113] Use GPU with device ID 0
I0418 18:16:58.321185 24121 caffe.cpp:121] Starting Optimization
I0418 18:16:58.321291 24121 solver.cpp:32] Initializing solver from parameters: 
test_iter: 1
test_interval: 10000000
base_lr: 0.001
display: 20
max_iter: 80000
lr_policy: "step"
gamma: 1
momentum: 0.9
weight_decay: 0.0005
stepsize: 10000000
snapshot: 1000
snapshot_prefix: "/home/pierre/hgRepos/models/caffeSegNet/train_segnet-pascal_lmdb/dropout_weighting/train/train"
solver_mode: GPU
net: "/home/pierre/hgRepos/models/caffeSegNet/train_segnet-pascal_lmdb/dropout_weighting/train_val.prototxt"
test_initialization: false
I0418 18:16:58.321329 24121 solver.cpp:70] Creating training net from net file: /home/pierre/hgRepos/models/caffeSegNet/train_segnet-pascal_lmdb/dropout_weighting/train_val.prototxt
I0418 18:16:58.323649 24121 net.cpp:287] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0418 18:16:58.323667 24121 net.cpp:287] The NetState phase (0) differed from the phase (1) specified by a rule in layer label
I0418 18:16:58.324481 24121 net.cpp:42] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_value: 104.00699
    mean_value: 116.66877
    mean_value: 122.67892
  }
  data_param {
    source: "/home/shared/datasets/VOCdevkit/VOC2012/LMDB/train_lmdb"
    batch_size: 2
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  include {
    phase: TRAIN
  }
  data_param {
    source: "/home/shared/datasets/VOCdevkit/VOC2012/LMDB/train_gt_lmdb"
    batch_size: 2
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_1_bn"
  type: "BN"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_2_bn"
  type: "BN"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1_drop"
  type: "Dropout"
  bottom: "conv1_2"
  top: "conv1_2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_bn"
  type: "BN"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2_bn"
  type: "BN"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_drop"
  type: "Dropout"
  bottom: "conv2_2"
  top: "conv2_2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn"
  type: "BN"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2_bn"
  type: "BN"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3_bn"
  type: "BN"
  bottom: "conv3_3"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3_drop"
  type: "Dropout"
  bottom: "conv3_3"
  top: "conv3_3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn"
  type: "BN"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2_bn"
  type: "BN"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_bn"
  type: "BN"
  bottom: "conv4_3"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4_drop"
  type: "Dropout"
  bottom: "conv4_3"
  top: "conv4_3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BN"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5_2_bn"
  type: "BN"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5_3_bn"
  type: "BN"
  bottom: "conv5_3"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5_drop"
  type: "Dropout"
  bottom: "conv5_3"
  top: "conv5_3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5_drop"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 32
    upsample_w: 32
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5_3_D_bn"
  type: "BN"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5_2_D_bn"
  type: "BN"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5_1_D_bn"
  type: "BN"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4_drop"
  type: "Dropout"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 63
    upsample_w: 63
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_D_bn"
  type: "BN"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2_D_bn"
  type: "BN"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_D_bn"
  type: "BN"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3_drop"
  type: "Dropout"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 125
    upsample_w: 125
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3_D_bn"
  type: "BN"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2_D_bn"
  type: "BN"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_D_bn"
  type: "BN"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2_drop"
  type: "Dropout"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2_D_bn"
  type: "BN"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_D_bn"
  type: "BN"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1_drop"
  type: "Dropout"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_2_D_bn"
  type: "BN"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    ignore_label: 21
    weight_by_label_freqs: true
    class_weighting: 0.2719
    class_weighting: 1.583
    class_weighting: 3.012
    class_weighting: 1.6572
    class_weighting: 1.7892
    class_weighting: 1.7815
    class_weighting: 0.5962
    class_weighting: 1.2053
    class_weighting: 0.674
    class_weighting: 1.8299
    class_weighting: 0.9166
    class_weighting: 0.8532
    class_weighting: 0.8935
    class_weighting: 0.9973
    class_weighting: 0.9742
    class_weighting: 1.1778
    class_weighting: 1.9162
    class_weighting: 1
    class_weighting: 0.8758
    class_weighting: 0.7225
    class_weighting: 1.3287
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0418 18:16:58.325080 24121 layer_factory.hpp:74] Creating layer data
I0418 18:16:58.325115 24121 net.cpp:90] Creating Layer data
I0418 18:16:58.325129 24121 net.cpp:368] data -> data
I0418 18:16:58.325161 24121 net.cpp:120] Setting up data
I0418 18:16:58.325263 24121 db.cpp:34] Opened lmdb /home/shared/datasets/VOCdevkit/VOC2012/LMDB/train_lmdb
I0418 18:16:58.326259 24121 data_layer.cpp:52] output data size: 2,3,500,500
I0418 18:16:58.328670 24121 net.cpp:127] Top shape: 2 3 500 500 (1500000)
I0418 18:16:58.328696 24121 layer_factory.hpp:74] Creating layer label
I0418 18:16:58.328718 24121 net.cpp:90] Creating Layer label
I0418 18:16:58.328729 24121 net.cpp:368] label -> label
I0418 18:16:58.328748 24121 net.cpp:120] Setting up label
I0418 18:16:58.328835 24121 db.cpp:34] Opened lmdb /home/shared/datasets/VOCdevkit/VOC2012/LMDB/train_gt_lmdb
I0418 18:16:58.329030 24121 data_layer.cpp:52] output data size: 2,1,500,500
I0418 18:16:58.329643 24121 net.cpp:127] Top shape: 2 1 500 500 (500000)
I0418 18:16:58.329658 24121 layer_factory.hpp:74] Creating layer label_label_0_split
I0418 18:16:58.329677 24121 net.cpp:90] Creating Layer label_label_0_split
I0418 18:16:58.329689 24121 net.cpp:410] label_label_0_split <- label
I0418 18:16:58.329706 24121 net.cpp:368] label_label_0_split -> label_label_0_split_0
I0418 18:16:58.329721 24121 net.cpp:368] label_label_0_split -> label_label_0_split_1
I0418 18:16:58.329733 24121 net.cpp:120] Setting up label_label_0_split
I0418 18:16:58.329747 24121 net.cpp:127] Top shape: 2 1 500 500 (500000)
I0418 18:16:58.329758 24121 net.cpp:127] Top shape: 2 1 500 500 (500000)
I0418 18:16:58.329766 24121 layer_factory.hpp:74] Creating layer conv1_1
I0418 18:16:58.329782 24121 net.cpp:90] Creating Layer conv1_1
I0418 18:16:58.329790 24121 net.cpp:410] conv1_1 <- data
I0418 18:16:58.329802 24121 net.cpp:368] conv1_1 -> conv1_1
I0418 18:16:58.329819 24121 net.cpp:120] Setting up conv1_1
I0418 18:16:59.626595 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:16:59.626648 24121 layer_factory.hpp:74] Creating layer conv1_1_bn
I0418 18:16:59.626675 24121 net.cpp:90] Creating Layer conv1_1_bn
I0418 18:16:59.626684 24121 net.cpp:410] conv1_1_bn <- conv1_1
I0418 18:16:59.626696 24121 net.cpp:357] conv1_1_bn -> conv1_1 (in-place)
I0418 18:16:59.626710 24121 net.cpp:120] Setting up conv1_1_bn
I0418 18:16:59.627637 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:16:59.627660 24121 layer_factory.hpp:74] Creating layer relu1_1
I0418 18:16:59.627683 24121 net.cpp:90] Creating Layer relu1_1
I0418 18:16:59.627698 24121 net.cpp:410] relu1_1 <- conv1_1
I0418 18:16:59.627712 24121 net.cpp:357] relu1_1 -> conv1_1 (in-place)
I0418 18:16:59.627724 24121 net.cpp:120] Setting up relu1_1
I0418 18:16:59.628135 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:16:59.628150 24121 layer_factory.hpp:74] Creating layer conv1_2
I0418 18:16:59.628170 24121 net.cpp:90] Creating Layer conv1_2
I0418 18:16:59.628183 24121 net.cpp:410] conv1_2 <- conv1_1
I0418 18:16:59.628198 24121 net.cpp:368] conv1_2 -> conv1_2
I0418 18:16:59.628221 24121 net.cpp:120] Setting up conv1_2
I0418 18:16:59.678155 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:16:59.678181 24121 layer_factory.hpp:74] Creating layer conv1_2_bn
I0418 18:16:59.678203 24121 net.cpp:90] Creating Layer conv1_2_bn
I0418 18:16:59.678236 24121 net.cpp:410] conv1_2_bn <- conv1_2
I0418 18:16:59.678251 24121 net.cpp:357] conv1_2_bn -> conv1_2 (in-place)
I0418 18:16:59.678270 24121 net.cpp:120] Setting up conv1_2_bn
I0418 18:16:59.679152 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:16:59.679175 24121 layer_factory.hpp:74] Creating layer relu1_2
I0418 18:16:59.679193 24121 net.cpp:90] Creating Layer relu1_2
I0418 18:16:59.679203 24121 net.cpp:410] relu1_2 <- conv1_2
I0418 18:16:59.679214 24121 net.cpp:357] relu1_2 -> conv1_2 (in-place)
I0418 18:16:59.679227 24121 net.cpp:120] Setting up relu1_2
I0418 18:16:59.681133 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:16:59.681148 24121 layer_factory.hpp:74] Creating layer pool1_drop
I0418 18:16:59.681160 24121 net.cpp:90] Creating Layer pool1_drop
I0418 18:16:59.681174 24121 net.cpp:410] pool1_drop <- conv1_2
I0418 18:16:59.681186 24121 net.cpp:357] pool1_drop -> conv1_2 (in-place)
I0418 18:16:59.681203 24121 net.cpp:120] Setting up pool1_drop
I0418 18:16:59.681221 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:16:59.681232 24121 layer_factory.hpp:74] Creating layer pool1
I0418 18:16:59.681244 24121 layer_factory.cpp:55] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0418 18:16:59.681258 24121 net.cpp:90] Creating Layer pool1
I0418 18:16:59.681272 24121 net.cpp:410] pool1 <- conv1_2
I0418 18:16:59.681285 24121 net.cpp:368] pool1 -> pool1
I0418 18:16:59.681301 24121 net.cpp:368] pool1 -> pool1_mask
I0418 18:16:59.681316 24121 net.cpp:120] Setting up pool1
I0418 18:16:59.681357 24121 net.cpp:127] Top shape: 2 64 250 250 (8000000)
I0418 18:16:59.681371 24121 net.cpp:127] Top shape: 2 64 250 250 (8000000)
I0418 18:16:59.681383 24121 layer_factory.hpp:74] Creating layer conv2_1
I0418 18:16:59.681401 24121 net.cpp:90] Creating Layer conv2_1
I0418 18:16:59.681411 24121 net.cpp:410] conv2_1 <- pool1
I0418 18:16:59.681426 24121 net.cpp:368] conv2_1 -> conv2_1
I0418 18:16:59.681445 24121 net.cpp:120] Setting up conv2_1
I0418 18:16:59.693110 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:16:59.693133 24121 layer_factory.hpp:74] Creating layer conv2_1_bn
I0418 18:16:59.693152 24121 net.cpp:90] Creating Layer conv2_1_bn
I0418 18:16:59.693163 24121 net.cpp:410] conv2_1_bn <- conv2_1
I0418 18:16:59.693177 24121 net.cpp:357] conv2_1_bn -> conv2_1 (in-place)
I0418 18:16:59.693197 24121 net.cpp:120] Setting up conv2_1_bn
I0418 18:16:59.693447 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:16:59.693466 24121 layer_factory.hpp:74] Creating layer relu2_1
I0418 18:16:59.693480 24121 net.cpp:90] Creating Layer relu2_1
I0418 18:16:59.693492 24121 net.cpp:410] relu2_1 <- conv2_1
I0418 18:16:59.693505 24121 net.cpp:357] relu2_1 -> conv2_1 (in-place)
I0418 18:16:59.693517 24121 net.cpp:120] Setting up relu2_1
I0418 18:16:59.697880 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:16:59.697893 24121 layer_factory.hpp:74] Creating layer conv2_2
I0418 18:16:59.697912 24121 net.cpp:90] Creating Layer conv2_2
I0418 18:16:59.697926 24121 net.cpp:410] conv2_2 <- conv2_1
I0418 18:16:59.697940 24121 net.cpp:368] conv2_2 -> conv2_2
I0418 18:16:59.697954 24121 net.cpp:120] Setting up conv2_2
I0418 18:16:59.731122 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:16:59.731147 24121 layer_factory.hpp:74] Creating layer conv2_2_bn
I0418 18:16:59.731164 24121 net.cpp:90] Creating Layer conv2_2_bn
I0418 18:16:59.731175 24121 net.cpp:410] conv2_2_bn <- conv2_2
I0418 18:16:59.731191 24121 net.cpp:357] conv2_2_bn -> conv2_2 (in-place)
I0418 18:16:59.731211 24121 net.cpp:120] Setting up conv2_2_bn
I0418 18:16:59.731462 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:16:59.731479 24121 layer_factory.hpp:74] Creating layer relu2_2
I0418 18:16:59.731498 24121 net.cpp:90] Creating Layer relu2_2
I0418 18:16:59.731518 24121 net.cpp:410] relu2_2 <- conv2_2
I0418 18:16:59.731530 24121 net.cpp:357] relu2_2 -> conv2_2 (in-place)
I0418 18:16:59.731544 24121 net.cpp:120] Setting up relu2_2
I0418 18:16:59.737082 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:16:59.737097 24121 layer_factory.hpp:74] Creating layer pool2_drop
I0418 18:16:59.737113 24121 net.cpp:90] Creating Layer pool2_drop
I0418 18:16:59.737128 24121 net.cpp:410] pool2_drop <- conv2_2
I0418 18:16:59.737139 24121 net.cpp:357] pool2_drop -> conv2_2 (in-place)
I0418 18:16:59.737152 24121 net.cpp:120] Setting up pool2_drop
I0418 18:16:59.737166 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:16:59.737176 24121 layer_factory.hpp:74] Creating layer pool2
I0418 18:16:59.737185 24121 layer_factory.cpp:55] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0418 18:16:59.737197 24121 net.cpp:90] Creating Layer pool2
I0418 18:16:59.737206 24121 net.cpp:410] pool2 <- conv2_2
I0418 18:16:59.737221 24121 net.cpp:368] pool2 -> pool2
I0418 18:16:59.737242 24121 net.cpp:368] pool2 -> pool2_mask
I0418 18:16:59.737260 24121 net.cpp:120] Setting up pool2
I0418 18:16:59.737279 24121 net.cpp:127] Top shape: 2 128 125 125 (4000000)
I0418 18:16:59.737293 24121 net.cpp:127] Top shape: 2 128 125 125 (4000000)
I0418 18:16:59.737305 24121 layer_factory.hpp:74] Creating layer conv3_1
I0418 18:16:59.737323 24121 net.cpp:90] Creating Layer conv3_1
I0418 18:16:59.737334 24121 net.cpp:410] conv3_1 <- pool2
I0418 18:16:59.737349 24121 net.cpp:368] conv3_1 -> conv3_1
I0418 18:16:59.737368 24121 net.cpp:120] Setting up conv3_1
I0418 18:16:59.783303 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:16:59.783329 24121 layer_factory.hpp:74] Creating layer conv3_1_bn
I0418 18:16:59.783354 24121 net.cpp:90] Creating Layer conv3_1_bn
I0418 18:16:59.783367 24121 net.cpp:410] conv3_1_bn <- conv3_1
I0418 18:16:59.783380 24121 net.cpp:357] conv3_1_bn -> conv3_1 (in-place)
I0418 18:16:59.783401 24121 net.cpp:120] Setting up conv3_1_bn
I0418 18:16:59.783490 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:16:59.783515 24121 layer_factory.hpp:74] Creating layer relu3_1
I0418 18:16:59.783529 24121 net.cpp:90] Creating Layer relu3_1
I0418 18:16:59.783541 24121 net.cpp:410] relu3_1 <- conv3_1
I0418 18:16:59.783555 24121 net.cpp:357] relu3_1 -> conv3_1 (in-place)
I0418 18:16:59.783572 24121 net.cpp:120] Setting up relu3_1
I0418 18:16:59.786622 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:16:59.786635 24121 layer_factory.hpp:74] Creating layer conv3_2
I0418 18:16:59.786653 24121 net.cpp:90] Creating Layer conv3_2
I0418 18:16:59.786666 24121 net.cpp:410] conv3_2 <- conv3_1
I0418 18:16:59.786680 24121 net.cpp:368] conv3_2 -> conv3_2
I0418 18:16:59.786695 24121 net.cpp:120] Setting up conv3_2
I0418 18:16:59.903664 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:16:59.903687 24121 layer_factory.hpp:74] Creating layer conv3_2_bn
I0418 18:16:59.903703 24121 net.cpp:90] Creating Layer conv3_2_bn
I0418 18:16:59.903717 24121 net.cpp:410] conv3_2_bn <- conv3_2
I0418 18:16:59.903733 24121 net.cpp:357] conv3_2_bn -> conv3_2 (in-place)
I0418 18:16:59.903748 24121 net.cpp:120] Setting up conv3_2_bn
I0418 18:16:59.903841 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:16:59.903861 24121 layer_factory.hpp:74] Creating layer relu3_2
I0418 18:16:59.903873 24121 net.cpp:90] Creating Layer relu3_2
I0418 18:16:59.903883 24121 net.cpp:410] relu3_2 <- conv3_2
I0418 18:16:59.903895 24121 net.cpp:357] relu3_2 -> conv3_2 (in-place)
I0418 18:16:59.903908 24121 net.cpp:120] Setting up relu3_2
I0418 18:16:59.914058 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:16:59.914072 24121 layer_factory.hpp:74] Creating layer conv3_3
I0418 18:16:59.914095 24121 net.cpp:90] Creating Layer conv3_3
I0418 18:16:59.914106 24121 net.cpp:410] conv3_3 <- conv3_2
I0418 18:16:59.914120 24121 net.cpp:368] conv3_3 -> conv3_3
I0418 18:16:59.914135 24121 net.cpp:120] Setting up conv3_3
I0418 18:16:59.932411 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:16:59.932435 24121 layer_factory.hpp:74] Creating layer conv3_3_bn
I0418 18:16:59.932457 24121 net.cpp:90] Creating Layer conv3_3_bn
I0418 18:16:59.932494 24121 net.cpp:410] conv3_3_bn <- conv3_3
I0418 18:16:59.932509 24121 net.cpp:357] conv3_3_bn -> conv3_3 (in-place)
I0418 18:16:59.932528 24121 net.cpp:120] Setting up conv3_3_bn
I0418 18:16:59.932618 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:16:59.932642 24121 layer_factory.hpp:74] Creating layer relu3_3
I0418 18:16:59.932658 24121 net.cpp:90] Creating Layer relu3_3
I0418 18:16:59.932668 24121 net.cpp:410] relu3_3 <- conv3_3
I0418 18:16:59.932680 24121 net.cpp:357] relu3_3 -> conv3_3 (in-place)
I0418 18:16:59.932699 24121 net.cpp:120] Setting up relu3_3
I0418 18:16:59.935858 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:16:59.935873 24121 layer_factory.hpp:74] Creating layer pool3_drop
I0418 18:16:59.935889 24121 net.cpp:90] Creating Layer pool3_drop
I0418 18:16:59.935901 24121 net.cpp:410] pool3_drop <- conv3_3
I0418 18:16:59.935914 24121 net.cpp:357] pool3_drop -> conv3_3 (in-place)
I0418 18:16:59.935926 24121 net.cpp:120] Setting up pool3_drop
I0418 18:16:59.935941 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:16:59.935956 24121 layer_factory.hpp:74] Creating layer pool3
I0418 18:16:59.935967 24121 layer_factory.cpp:55] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0418 18:16:59.935979 24121 net.cpp:90] Creating Layer pool3
I0418 18:16:59.935988 24121 net.cpp:410] pool3 <- conv3_3
I0418 18:16:59.936004 24121 net.cpp:368] pool3 -> pool3
I0418 18:16:59.936022 24121 net.cpp:368] pool3 -> pool3_mask
I0418 18:16:59.936041 24121 net.cpp:120] Setting up pool3
I0418 18:16:59.936061 24121 net.cpp:127] Top shape: 2 256 63 63 (2032128)
I0418 18:16:59.936080 24121 net.cpp:127] Top shape: 2 256 63 63 (2032128)
I0418 18:16:59.936091 24121 layer_factory.hpp:74] Creating layer conv4_1
I0418 18:16:59.936107 24121 net.cpp:90] Creating Layer conv4_1
I0418 18:16:59.936120 24121 net.cpp:410] conv4_1 <- pool3
I0418 18:16:59.936137 24121 net.cpp:368] conv4_1 -> conv4_1
I0418 18:16:59.936151 24121 net.cpp:120] Setting up conv4_1
I0418 18:16:59.950160 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:16:59.950193 24121 layer_factory.hpp:74] Creating layer conv4_1_bn
I0418 18:16:59.950215 24121 net.cpp:90] Creating Layer conv4_1_bn
I0418 18:16:59.950229 24121 net.cpp:410] conv4_1_bn <- conv4_1
I0418 18:16:59.950244 24121 net.cpp:357] conv4_1_bn -> conv4_1 (in-place)
I0418 18:16:59.950260 24121 net.cpp:120] Setting up conv4_1_bn
I0418 18:16:59.950306 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:16:59.950323 24121 layer_factory.hpp:74] Creating layer relu4_1
I0418 18:16:59.950350 24121 net.cpp:90] Creating Layer relu4_1
I0418 18:16:59.950363 24121 net.cpp:410] relu4_1 <- conv4_1
I0418 18:16:59.950377 24121 net.cpp:357] relu4_1 -> conv4_1 (in-place)
I0418 18:16:59.950390 24121 net.cpp:120] Setting up relu4_1
I0418 18:16:59.955066 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:16:59.955080 24121 layer_factory.hpp:74] Creating layer conv4_2
I0418 18:16:59.955099 24121 net.cpp:90] Creating Layer conv4_2
I0418 18:16:59.955118 24121 net.cpp:410] conv4_2 <- conv4_1
I0418 18:16:59.955137 24121 net.cpp:368] conv4_2 -> conv4_2
I0418 18:16:59.955152 24121 net.cpp:120] Setting up conv4_2
I0418 18:16:59.978489 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:16:59.978543 24121 layer_factory.hpp:74] Creating layer conv4_2_bn
I0418 18:16:59.978564 24121 net.cpp:90] Creating Layer conv4_2_bn
I0418 18:16:59.978577 24121 net.cpp:410] conv4_2_bn <- conv4_2
I0418 18:16:59.978595 24121 net.cpp:357] conv4_2_bn -> conv4_2 (in-place)
I0418 18:16:59.978612 24121 net.cpp:120] Setting up conv4_2_bn
I0418 18:16:59.978672 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:16:59.978693 24121 layer_factory.hpp:74] Creating layer relu4_2
I0418 18:16:59.978713 24121 net.cpp:90] Creating Layer relu4_2
I0418 18:16:59.978723 24121 net.cpp:410] relu4_2 <- conv4_2
I0418 18:16:59.978735 24121 net.cpp:357] relu4_2 -> conv4_2 (in-place)
I0418 18:16:59.978747 24121 net.cpp:120] Setting up relu4_2
I0418 18:16:59.982704 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:16:59.982735 24121 layer_factory.hpp:74] Creating layer conv4_3
I0418 18:16:59.982763 24121 net.cpp:90] Creating Layer conv4_3
I0418 18:16:59.982779 24121 net.cpp:410] conv4_3 <- conv4_2
I0418 18:16:59.982796 24121 net.cpp:368] conv4_3 -> conv4_3
I0418 18:16:59.982815 24121 net.cpp:120] Setting up conv4_3
I0418 18:17:00.008149 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.008195 24121 layer_factory.hpp:74] Creating layer conv4_3_bn
I0418 18:17:00.008219 24121 net.cpp:90] Creating Layer conv4_3_bn
I0418 18:17:00.008232 24121 net.cpp:410] conv4_3_bn <- conv4_3
I0418 18:17:00.008247 24121 net.cpp:357] conv4_3_bn -> conv4_3 (in-place)
I0418 18:17:00.008265 24121 net.cpp:120] Setting up conv4_3_bn
I0418 18:17:00.008312 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.008329 24121 layer_factory.hpp:74] Creating layer relu4_3
I0418 18:17:00.008347 24121 net.cpp:90] Creating Layer relu4_3
I0418 18:17:00.008360 24121 net.cpp:410] relu4_3 <- conv4_3
I0418 18:17:00.008373 24121 net.cpp:357] relu4_3 -> conv4_3 (in-place)
I0418 18:17:00.008385 24121 net.cpp:120] Setting up relu4_3
I0418 18:17:00.011822 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.011837 24121 layer_factory.hpp:74] Creating layer pool4_drop
I0418 18:17:00.011853 24121 net.cpp:90] Creating Layer pool4_drop
I0418 18:17:00.011867 24121 net.cpp:410] pool4_drop <- conv4_3
I0418 18:17:00.011878 24121 net.cpp:357] pool4_drop -> conv4_3 (in-place)
I0418 18:17:00.011893 24121 net.cpp:120] Setting up pool4_drop
I0418 18:17:00.011907 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.011917 24121 layer_factory.hpp:74] Creating layer pool4
I0418 18:17:00.011939 24121 layer_factory.cpp:55] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0418 18:17:00.011960 24121 net.cpp:90] Creating Layer pool4
I0418 18:17:00.011971 24121 net.cpp:410] pool4 <- conv4_3
I0418 18:17:00.011986 24121 net.cpp:368] pool4 -> pool4
I0418 18:17:00.012006 24121 net.cpp:368] pool4 -> pool4_mask
I0418 18:17:00.012022 24121 net.cpp:120] Setting up pool4
I0418 18:17:00.012039 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.012054 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.012063 24121 layer_factory.hpp:74] Creating layer conv5_1
I0418 18:17:00.012082 24121 net.cpp:90] Creating Layer conv5_1
I0418 18:17:00.012095 24121 net.cpp:410] conv5_1 <- pool4
I0418 18:17:00.012111 24121 net.cpp:368] conv5_1 -> conv5_1
I0418 18:17:00.012131 24121 net.cpp:120] Setting up conv5_1
I0418 18:17:00.038974 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.039013 24121 layer_factory.hpp:74] Creating layer conv5_1_bn
I0418 18:17:00.039034 24121 net.cpp:90] Creating Layer conv5_1_bn
I0418 18:17:00.039048 24121 net.cpp:410] conv5_1_bn <- conv5_1
I0418 18:17:00.039065 24121 net.cpp:357] conv5_1_bn -> conv5_1 (in-place)
I0418 18:17:00.039083 24121 net.cpp:120] Setting up conv5_1_bn
I0418 18:17:00.039126 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.039147 24121 layer_factory.hpp:74] Creating layer relu5_1
I0418 18:17:00.039170 24121 net.cpp:90] Creating Layer relu5_1
I0418 18:17:00.039180 24121 net.cpp:410] relu5_1 <- conv5_1
I0418 18:17:00.039192 24121 net.cpp:357] relu5_1 -> conv5_1 (in-place)
I0418 18:17:00.039212 24121 net.cpp:120] Setting up relu5_1
I0418 18:17:00.042701 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.042717 24121 layer_factory.hpp:74] Creating layer conv5_2
I0418 18:17:00.042742 24121 net.cpp:90] Creating Layer conv5_2
I0418 18:17:00.042758 24121 net.cpp:410] conv5_2 <- conv5_1
I0418 18:17:00.042773 24121 net.cpp:368] conv5_2 -> conv5_2
I0418 18:17:00.042793 24121 net.cpp:120] Setting up conv5_2
I0418 18:17:00.065819 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.065863 24121 layer_factory.hpp:74] Creating layer conv5_2_bn
I0418 18:17:00.065884 24121 net.cpp:90] Creating Layer conv5_2_bn
I0418 18:17:00.065896 24121 net.cpp:410] conv5_2_bn <- conv5_2
I0418 18:17:00.065948 24121 net.cpp:357] conv5_2_bn -> conv5_2 (in-place)
I0418 18:17:00.065979 24121 net.cpp:120] Setting up conv5_2_bn
I0418 18:17:00.066032 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.066051 24121 layer_factory.hpp:74] Creating layer relu5_2
I0418 18:17:00.066068 24121 net.cpp:90] Creating Layer relu5_2
I0418 18:17:00.066082 24121 net.cpp:410] relu5_2 <- conv5_2
I0418 18:17:00.066098 24121 net.cpp:357] relu5_2 -> conv5_2 (in-place)
I0418 18:17:00.066112 24121 net.cpp:120] Setting up relu5_2
I0418 18:17:00.069255 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.069270 24121 layer_factory.hpp:74] Creating layer conv5_3
I0418 18:17:00.069288 24121 net.cpp:90] Creating Layer conv5_3
I0418 18:17:00.069301 24121 net.cpp:410] conv5_3 <- conv5_2
I0418 18:17:00.069319 24121 net.cpp:368] conv5_3 -> conv5_3
I0418 18:17:00.069334 24121 net.cpp:120] Setting up conv5_3
I0418 18:17:00.094980 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.095024 24121 layer_factory.hpp:74] Creating layer conv5_3_bn
I0418 18:17:00.095046 24121 net.cpp:90] Creating Layer conv5_3_bn
I0418 18:17:00.095060 24121 net.cpp:410] conv5_3_bn <- conv5_3
I0418 18:17:00.095077 24121 net.cpp:357] conv5_3_bn -> conv5_3 (in-place)
I0418 18:17:00.095094 24121 net.cpp:120] Setting up conv5_3_bn
I0418 18:17:00.095144 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.095163 24121 layer_factory.hpp:74] Creating layer relu5_3
I0418 18:17:00.095185 24121 net.cpp:90] Creating Layer relu5_3
I0418 18:17:00.095199 24121 net.cpp:410] relu5_3 <- conv5_3
I0418 18:17:00.095212 24121 net.cpp:357] relu5_3 -> conv5_3 (in-place)
I0418 18:17:00.095224 24121 net.cpp:120] Setting up relu5_3
I0418 18:17:00.097950 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.097965 24121 layer_factory.hpp:74] Creating layer pool5_drop
I0418 18:17:00.097978 24121 net.cpp:90] Creating Layer pool5_drop
I0418 18:17:00.097990 24121 net.cpp:410] pool5_drop <- conv5_3
I0418 18:17:00.098006 24121 net.cpp:357] pool5_drop -> conv5_3 (in-place)
I0418 18:17:00.098021 24121 net.cpp:120] Setting up pool5_drop
I0418 18:17:00.098040 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.098052 24121 layer_factory.hpp:74] Creating layer pool5
I0418 18:17:00.098064 24121 layer_factory.cpp:55] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0418 18:17:00.098076 24121 net.cpp:90] Creating Layer pool5
I0418 18:17:00.098085 24121 net.cpp:410] pool5 <- conv5_3
I0418 18:17:00.098101 24121 net.cpp:368] pool5 -> pool5
I0418 18:17:00.098119 24121 net.cpp:368] pool5 -> pool5_mask
I0418 18:17:00.098136 24121 net.cpp:120] Setting up pool5
I0418 18:17:00.098156 24121 net.cpp:127] Top shape: 2 512 16 16 (262144)
I0418 18:17:00.098171 24121 net.cpp:127] Top shape: 2 512 16 16 (262144)
I0418 18:17:00.098186 24121 layer_factory.hpp:74] Creating layer upsample5_drop
I0418 18:17:00.098199 24121 net.cpp:90] Creating Layer upsample5_drop
I0418 18:17:00.098209 24121 net.cpp:410] upsample5_drop <- pool5
I0418 18:17:00.098222 24121 net.cpp:357] upsample5_drop -> pool5 (in-place)
I0418 18:17:00.098233 24121 net.cpp:120] Setting up upsample5_drop
I0418 18:17:00.098250 24121 net.cpp:127] Top shape: 2 512 16 16 (262144)
I0418 18:17:00.098261 24121 layer_factory.hpp:74] Creating layer upsample5
I0418 18:17:00.098283 24121 net.cpp:90] Creating Layer upsample5
I0418 18:17:00.098296 24121 net.cpp:410] upsample5 <- pool5
I0418 18:17:00.098309 24121 net.cpp:410] upsample5 <- pool5_mask
I0418 18:17:00.098322 24121 net.cpp:368] upsample5 -> pool5_D
I0418 18:17:00.098340 24121 net.cpp:120] Setting up upsample5
I0418 18:17:00.098362 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.098376 24121 layer_factory.hpp:74] Creating layer conv5_3_D
I0418 18:17:00.098395 24121 net.cpp:90] Creating Layer conv5_3_D
I0418 18:17:00.098409 24121 net.cpp:410] conv5_3_D <- pool5_D
I0418 18:17:00.098424 24121 net.cpp:368] conv5_3_D -> conv5_3_D
I0418 18:17:00.098439 24121 net.cpp:120] Setting up conv5_3_D
I0418 18:17:00.122503 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.122546 24121 layer_factory.hpp:74] Creating layer conv5_3_D_bn
I0418 18:17:00.122570 24121 net.cpp:90] Creating Layer conv5_3_D_bn
I0418 18:17:00.122584 24121 net.cpp:410] conv5_3_D_bn <- conv5_3_D
I0418 18:17:00.122601 24121 net.cpp:357] conv5_3_D_bn -> conv5_3_D (in-place)
I0418 18:17:00.122617 24121 net.cpp:120] Setting up conv5_3_D_bn
I0418 18:17:00.122654 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.122679 24121 layer_factory.hpp:74] Creating layer relu5_3_D
I0418 18:17:00.122697 24121 net.cpp:90] Creating Layer relu5_3_D
I0418 18:17:00.122714 24121 net.cpp:410] relu5_3_D <- conv5_3_D
I0418 18:17:00.122730 24121 net.cpp:357] relu5_3_D -> conv5_3_D (in-place)
I0418 18:17:00.122745 24121 net.cpp:120] Setting up relu5_3_D
I0418 18:17:00.125627 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.125644 24121 layer_factory.hpp:74] Creating layer conv5_2_D
I0418 18:17:00.125663 24121 net.cpp:90] Creating Layer conv5_2_D
I0418 18:17:00.125677 24121 net.cpp:410] conv5_2_D <- conv5_3_D
I0418 18:17:00.125691 24121 net.cpp:368] conv5_2_D -> conv5_2_D
I0418 18:17:00.125715 24121 net.cpp:120] Setting up conv5_2_D
I0418 18:17:00.151695 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.151739 24121 layer_factory.hpp:74] Creating layer conv5_2_D_bn
I0418 18:17:00.151764 24121 net.cpp:90] Creating Layer conv5_2_D_bn
I0418 18:17:00.151779 24121 net.cpp:410] conv5_2_D_bn <- conv5_2_D
I0418 18:17:00.151793 24121 net.cpp:357] conv5_2_D_bn -> conv5_2_D (in-place)
I0418 18:17:00.151809 24121 net.cpp:120] Setting up conv5_2_D_bn
I0418 18:17:00.151845 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.151865 24121 layer_factory.hpp:74] Creating layer relu5_2_D
I0418 18:17:00.151887 24121 net.cpp:90] Creating Layer relu5_2_D
I0418 18:17:00.151901 24121 net.cpp:410] relu5_2_D <- conv5_2_D
I0418 18:17:00.151917 24121 net.cpp:357] relu5_2_D -> conv5_2_D (in-place)
I0418 18:17:00.151934 24121 net.cpp:120] Setting up relu5_2_D
I0418 18:17:00.154443 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.154458 24121 layer_factory.hpp:74] Creating layer conv5_1_D
I0418 18:17:00.154477 24121 net.cpp:90] Creating Layer conv5_1_D
I0418 18:17:00.154491 24121 net.cpp:410] conv5_1_D <- conv5_2_D
I0418 18:17:00.154508 24121 net.cpp:368] conv5_1_D -> conv5_1_D
I0418 18:17:00.154527 24121 net.cpp:120] Setting up conv5_1_D
I0418 18:17:00.179360 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.179404 24121 layer_factory.hpp:74] Creating layer conv5_1_D_bn
I0418 18:17:00.179432 24121 net.cpp:90] Creating Layer conv5_1_D_bn
I0418 18:17:00.179443 24121 net.cpp:410] conv5_1_D_bn <- conv5_1_D
I0418 18:17:00.179461 24121 net.cpp:357] conv5_1_D_bn -> conv5_1_D (in-place)
I0418 18:17:00.179478 24121 net.cpp:120] Setting up conv5_1_D_bn
I0418 18:17:00.179533 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.179550 24121 layer_factory.hpp:74] Creating layer relu5_1_D
I0418 18:17:00.179576 24121 net.cpp:90] Creating Layer relu5_1_D
I0418 18:17:00.179587 24121 net.cpp:410] relu5_1_D <- conv5_1_D
I0418 18:17:00.179600 24121 net.cpp:357] relu5_1_D -> conv5_1_D (in-place)
I0418 18:17:00.179617 24121 net.cpp:120] Setting up relu5_1_D
I0418 18:17:00.183189 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.183204 24121 layer_factory.hpp:74] Creating layer upsample4_drop
I0418 18:17:00.183218 24121 net.cpp:90] Creating Layer upsample4_drop
I0418 18:17:00.183230 24121 net.cpp:410] upsample4_drop <- conv5_1_D
I0418 18:17:00.183243 24121 net.cpp:357] upsample4_drop -> conv5_1_D (in-place)
I0418 18:17:00.183256 24121 net.cpp:120] Setting up upsample4_drop
I0418 18:17:00.183271 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.183290 24121 layer_factory.hpp:74] Creating layer upsample4
I0418 18:17:00.183325 24121 net.cpp:90] Creating Layer upsample4
I0418 18:17:00.183336 24121 net.cpp:410] upsample4 <- conv5_1_D
I0418 18:17:00.183377 24121 net.cpp:410] upsample4 <- pool4_mask
I0418 18:17:00.183392 24121 net.cpp:368] upsample4 -> pool4_D
I0418 18:17:00.183410 24121 net.cpp:120] Setting up upsample4
I0418 18:17:00.183430 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.183445 24121 layer_factory.hpp:74] Creating layer conv4_3_D
I0418 18:17:00.183465 24121 net.cpp:90] Creating Layer conv4_3_D
I0418 18:17:00.183478 24121 net.cpp:410] conv4_3_D <- pool4_D
I0418 18:17:00.183509 24121 net.cpp:368] conv4_3_D -> conv4_3_D
I0418 18:17:00.183533 24121 net.cpp:120] Setting up conv4_3_D
I0418 18:17:00.213731 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.213793 24121 layer_factory.hpp:74] Creating layer conv4_3_D_bn
I0418 18:17:00.213820 24121 net.cpp:90] Creating Layer conv4_3_D_bn
I0418 18:17:00.213832 24121 net.cpp:410] conv4_3_D_bn <- conv4_3_D
I0418 18:17:00.213851 24121 net.cpp:357] conv4_3_D_bn -> conv4_3_D (in-place)
I0418 18:17:00.213877 24121 net.cpp:120] Setting up conv4_3_D_bn
I0418 18:17:00.213927 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.213943 24121 layer_factory.hpp:74] Creating layer relu4_3_D
I0418 18:17:00.213960 24121 net.cpp:90] Creating Layer relu4_3_D
I0418 18:17:00.213974 24121 net.cpp:410] relu4_3_D <- conv4_3_D
I0418 18:17:00.213987 24121 net.cpp:357] relu4_3_D -> conv4_3_D (in-place)
I0418 18:17:00.214000 24121 net.cpp:120] Setting up relu4_3_D
I0418 18:17:00.216271 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.216286 24121 layer_factory.hpp:74] Creating layer conv4_2_D
I0418 18:17:00.216303 24121 net.cpp:90] Creating Layer conv4_2_D
I0418 18:17:00.216316 24121 net.cpp:410] conv4_2_D <- conv4_3_D
I0418 18:17:00.216333 24121 net.cpp:368] conv4_2_D -> conv4_2_D
I0418 18:17:00.216358 24121 net.cpp:120] Setting up conv4_2_D
I0418 18:17:00.245177 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.245223 24121 layer_factory.hpp:74] Creating layer conv4_2_D_bn
I0418 18:17:00.245245 24121 net.cpp:90] Creating Layer conv4_2_D_bn
I0418 18:17:00.245260 24121 net.cpp:410] conv4_2_D_bn <- conv4_2_D
I0418 18:17:00.245275 24121 net.cpp:357] conv4_2_D_bn -> conv4_2_D (in-place)
I0418 18:17:00.245291 24121 net.cpp:120] Setting up conv4_2_D_bn
I0418 18:17:00.245343 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.245360 24121 layer_factory.hpp:74] Creating layer relu4_2_D
I0418 18:17:00.245375 24121 net.cpp:90] Creating Layer relu4_2_D
I0418 18:17:00.245385 24121 net.cpp:410] relu4_2_D <- conv4_2_D
I0418 18:17:00.245398 24121 net.cpp:357] relu4_2_D -> conv4_2_D (in-place)
I0418 18:17:00.245415 24121 net.cpp:120] Setting up relu4_2_D
I0418 18:17:00.250335 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.250354 24121 layer_factory.hpp:74] Creating layer conv4_1_D
I0418 18:17:00.250373 24121 net.cpp:90] Creating Layer conv4_1_D
I0418 18:17:00.250387 24121 net.cpp:410] conv4_1_D <- conv4_2_D
I0418 18:17:00.250401 24121 net.cpp:368] conv4_1_D -> conv4_1_D
I0418 18:17:00.250422 24121 net.cpp:120] Setting up conv4_1_D
I0418 18:17:00.263825 24121 net.cpp:127] Top shape: 2 256 63 63 (2032128)
I0418 18:17:00.263852 24121 layer_factory.hpp:74] Creating layer conv4_1_D_bn
I0418 18:17:00.263871 24121 net.cpp:90] Creating Layer conv4_1_D_bn
I0418 18:17:00.263885 24121 net.cpp:410] conv4_1_D_bn <- conv4_1_D
I0418 18:17:00.263902 24121 net.cpp:357] conv4_1_D_bn -> conv4_1_D (in-place)
I0418 18:17:00.263918 24121 net.cpp:120] Setting up conv4_1_D_bn
I0418 18:17:00.263965 24121 net.cpp:127] Top shape: 2 256 63 63 (2032128)
I0418 18:17:00.263984 24121 layer_factory.hpp:74] Creating layer relu4_1_D
I0418 18:17:00.264004 24121 net.cpp:90] Creating Layer relu4_1_D
I0418 18:17:00.264019 24121 net.cpp:410] relu4_1_D <- conv4_1_D
I0418 18:17:00.264031 24121 net.cpp:357] relu4_1_D -> conv4_1_D (in-place)
I0418 18:17:00.264050 24121 net.cpp:120] Setting up relu4_1_D
I0418 18:17:00.266136 24121 net.cpp:127] Top shape: 2 256 63 63 (2032128)
I0418 18:17:00.266150 24121 layer_factory.hpp:74] Creating layer upsample3_drop
I0418 18:17:00.266199 24121 net.cpp:90] Creating Layer upsample3_drop
I0418 18:17:00.266211 24121 net.cpp:410] upsample3_drop <- conv4_1_D
I0418 18:17:00.266224 24121 net.cpp:357] upsample3_drop -> conv4_1_D (in-place)
I0418 18:17:00.266237 24121 net.cpp:120] Setting up upsample3_drop
I0418 18:17:00.266253 24121 net.cpp:127] Top shape: 2 256 63 63 (2032128)
I0418 18:17:00.266264 24121 layer_factory.hpp:74] Creating layer upsample3
I0418 18:17:00.266280 24121 net.cpp:90] Creating Layer upsample3
I0418 18:17:00.266294 24121 net.cpp:410] upsample3 <- conv4_1_D
I0418 18:17:00.266306 24121 net.cpp:410] upsample3 <- pool3_mask
I0418 18:17:00.266324 24121 net.cpp:368] upsample3 -> pool3_D
I0418 18:17:00.266341 24121 net.cpp:120] Setting up upsample3
I0418 18:17:00.266358 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:00.266372 24121 layer_factory.hpp:74] Creating layer conv3_3_D
I0418 18:17:00.266388 24121 net.cpp:90] Creating Layer conv3_3_D
I0418 18:17:00.266397 24121 net.cpp:410] conv3_3_D <- pool3_D
I0418 18:17:00.266414 24121 net.cpp:368] conv3_3_D -> conv3_3_D
I0418 18:17:00.266433 24121 net.cpp:120] Setting up conv3_3_D
I0418 18:17:00.296809 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:00.296834 24121 layer_factory.hpp:74] Creating layer conv3_3_D_bn
I0418 18:17:00.296856 24121 net.cpp:90] Creating Layer conv3_3_D_bn
I0418 18:17:00.296870 24121 net.cpp:410] conv3_3_D_bn <- conv3_3_D
I0418 18:17:00.296885 24121 net.cpp:357] conv3_3_D_bn -> conv3_3_D (in-place)
I0418 18:17:00.296900 24121 net.cpp:120] Setting up conv3_3_D_bn
I0418 18:17:00.296994 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:00.297013 24121 layer_factory.hpp:74] Creating layer relu3_3_D
I0418 18:17:00.297027 24121 net.cpp:90] Creating Layer relu3_3_D
I0418 18:17:00.297037 24121 net.cpp:410] relu3_3_D <- conv3_3_D
I0418 18:17:00.297052 24121 net.cpp:357] relu3_3_D -> conv3_3_D (in-place)
I0418 18:17:00.297071 24121 net.cpp:120] Setting up relu3_3_D
I0418 18:17:00.299290 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:00.299307 24121 layer_factory.hpp:74] Creating layer conv3_2_D
I0418 18:17:00.299324 24121 net.cpp:90] Creating Layer conv3_2_D
I0418 18:17:00.299340 24121 net.cpp:410] conv3_2_D <- conv3_3_D
I0418 18:17:00.299356 24121 net.cpp:368] conv3_2_D -> conv3_2_D
I0418 18:17:00.299379 24121 net.cpp:120] Setting up conv3_2_D
I0418 18:17:00.308818 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:00.308840 24121 layer_factory.hpp:74] Creating layer conv3_2_D_bn
I0418 18:17:00.308863 24121 net.cpp:90] Creating Layer conv3_2_D_bn
I0418 18:17:00.308876 24121 net.cpp:410] conv3_2_D_bn <- conv3_2_D
I0418 18:17:00.308892 24121 net.cpp:357] conv3_2_D_bn -> conv3_2_D (in-place)
I0418 18:17:00.308912 24121 net.cpp:120] Setting up conv3_2_D_bn
I0418 18:17:00.309001 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:00.309022 24121 layer_factory.hpp:74] Creating layer relu3_2_D
I0418 18:17:00.309039 24121 net.cpp:90] Creating Layer relu3_2_D
I0418 18:17:00.309049 24121 net.cpp:410] relu3_2_D <- conv3_2_D
I0418 18:17:00.309064 24121 net.cpp:357] relu3_2_D -> conv3_2_D (in-place)
I0418 18:17:00.309082 24121 net.cpp:120] Setting up relu3_2_D
I0418 18:17:00.312724 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:00.312738 24121 layer_factory.hpp:74] Creating layer conv3_1_D
I0418 18:17:00.312757 24121 net.cpp:90] Creating Layer conv3_1_D
I0418 18:17:00.312770 24121 net.cpp:410] conv3_1_D <- conv3_2_D
I0418 18:17:00.312784 24121 net.cpp:368] conv3_1_D -> conv3_1_D
I0418 18:17:00.312810 24121 net.cpp:120] Setting up conv3_1_D
I0418 18:17:00.360003 24121 net.cpp:127] Top shape: 2 128 125 125 (4000000)
I0418 18:17:00.360023 24121 layer_factory.hpp:74] Creating layer conv3_1_D_bn
I0418 18:17:00.360044 24121 net.cpp:90] Creating Layer conv3_1_D_bn
I0418 18:17:00.360057 24121 net.cpp:410] conv3_1_D_bn <- conv3_1_D
I0418 18:17:00.360074 24121 net.cpp:357] conv3_1_D_bn -> conv3_1_D (in-place)
I0418 18:17:00.360092 24121 net.cpp:120] Setting up conv3_1_D_bn
I0418 18:17:00.360195 24121 net.cpp:127] Top shape: 2 128 125 125 (4000000)
I0418 18:17:00.360219 24121 layer_factory.hpp:74] Creating layer relu3_1_D
I0418 18:17:00.360231 24121 net.cpp:90] Creating Layer relu3_1_D
I0418 18:17:00.360244 24121 net.cpp:410] relu3_1_D <- conv3_1_D
I0418 18:17:00.360256 24121 net.cpp:357] relu3_1_D -> conv3_1_D (in-place)
I0418 18:17:00.360270 24121 net.cpp:120] Setting up relu3_1_D
I0418 18:17:00.362352 24121 net.cpp:127] Top shape: 2 128 125 125 (4000000)
I0418 18:17:00.362366 24121 layer_factory.hpp:74] Creating layer upsample2_drop
I0418 18:17:00.362380 24121 net.cpp:90] Creating Layer upsample2_drop
I0418 18:17:00.362390 24121 net.cpp:410] upsample2_drop <- conv3_1_D
I0418 18:17:00.362407 24121 net.cpp:357] upsample2_drop -> conv3_1_D (in-place)
I0418 18:17:00.362421 24121 net.cpp:120] Setting up upsample2_drop
I0418 18:17:00.362442 24121 net.cpp:127] Top shape: 2 128 125 125 (4000000)
I0418 18:17:00.362454 24121 layer_factory.hpp:74] Creating layer upsample2
I0418 18:17:00.362468 24121 net.cpp:90] Creating Layer upsample2
I0418 18:17:00.362480 24121 net.cpp:410] upsample2 <- conv3_1_D
I0418 18:17:00.362493 24121 net.cpp:410] upsample2 <- pool2_mask
I0418 18:17:00.362505 24121 net.cpp:368] upsample2 -> pool2_D
I0418 18:17:00.362520 24121 net.cpp:120] Setting up upsample2
I0418 18:17:00.362536 24121 upsample_layer.cpp:31] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0418 18:17:00.362557 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:17:00.362571 24121 layer_factory.hpp:74] Creating layer conv2_2_D
I0418 18:17:00.362589 24121 net.cpp:90] Creating Layer conv2_2_D
I0418 18:17:00.362602 24121 net.cpp:410] conv2_2_D <- pool2_D
I0418 18:17:00.362620 24121 net.cpp:368] conv2_2_D -> conv2_2_D
I0418 18:17:00.362637 24121 net.cpp:120] Setting up conv2_2_D
I0418 18:17:00.374358 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:17:00.374380 24121 layer_factory.hpp:74] Creating layer conv2_2_D_bn
I0418 18:17:00.374395 24121 net.cpp:90] Creating Layer conv2_2_D_bn
I0418 18:17:00.374405 24121 net.cpp:410] conv2_2_D_bn <- conv2_2_D
I0418 18:17:00.374421 24121 net.cpp:357] conv2_2_D_bn -> conv2_2_D (in-place)
I0418 18:17:00.374436 24121 net.cpp:120] Setting up conv2_2_D_bn
I0418 18:17:00.374689 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:17:00.374712 24121 layer_factory.hpp:74] Creating layer relu2_2_D
I0418 18:17:00.374725 24121 net.cpp:90] Creating Layer relu2_2_D
I0418 18:17:00.374735 24121 net.cpp:410] relu2_2_D <- conv2_2_D
I0418 18:17:00.374747 24121 net.cpp:357] relu2_2_D -> conv2_2_D (in-place)
I0418 18:17:00.374759 24121 net.cpp:120] Setting up relu2_2_D
I0418 18:17:00.378538 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:17:00.378553 24121 layer_factory.hpp:74] Creating layer conv2_1_D
I0418 18:17:00.378573 24121 net.cpp:90] Creating Layer conv2_1_D
I0418 18:17:00.378589 24121 net.cpp:410] conv2_1_D <- conv2_2_D
I0418 18:17:00.378603 24121 net.cpp:368] conv2_1_D -> conv2_1_D
I0418 18:17:00.378624 24121 net.cpp:120] Setting up conv2_1_D
I0418 18:17:00.407874 24121 net.cpp:127] Top shape: 2 64 250 250 (8000000)
I0418 18:17:00.407896 24121 layer_factory.hpp:74] Creating layer conv2_1_D_bn
I0418 18:17:00.407913 24121 net.cpp:90] Creating Layer conv2_1_D_bn
I0418 18:17:00.407923 24121 net.cpp:410] conv2_1_D_bn <- conv2_1_D
I0418 18:17:00.407937 24121 net.cpp:357] conv2_1_D_bn -> conv2_1_D (in-place)
I0418 18:17:00.407950 24121 net.cpp:120] Setting up conv2_1_D_bn
I0418 18:17:00.408203 24121 net.cpp:127] Top shape: 2 64 250 250 (8000000)
I0418 18:17:00.408222 24121 layer_factory.hpp:74] Creating layer relu2_1_D
I0418 18:17:00.408238 24121 net.cpp:90] Creating Layer relu2_1_D
I0418 18:17:00.408248 24121 net.cpp:410] relu2_1_D <- conv2_1_D
I0418 18:17:00.408262 24121 net.cpp:357] relu2_1_D -> conv2_1_D (in-place)
I0418 18:17:00.408279 24121 net.cpp:120] Setting up relu2_1_D
I0418 18:17:00.411574 24121 net.cpp:127] Top shape: 2 64 250 250 (8000000)
I0418 18:17:00.411594 24121 layer_factory.hpp:74] Creating layer upsample1_drop
I0418 18:17:00.411636 24121 net.cpp:90] Creating Layer upsample1_drop
I0418 18:17:00.411653 24121 net.cpp:410] upsample1_drop <- conv2_1_D
I0418 18:17:00.411670 24121 net.cpp:357] upsample1_drop -> conv2_1_D (in-place)
I0418 18:17:00.411686 24121 net.cpp:120] Setting up upsample1_drop
I0418 18:17:00.411707 24121 net.cpp:127] Top shape: 2 64 250 250 (8000000)
I0418 18:17:00.411720 24121 layer_factory.hpp:74] Creating layer upsample1
I0418 18:17:00.411732 24121 net.cpp:90] Creating Layer upsample1
I0418 18:17:00.411743 24121 net.cpp:410] upsample1 <- conv2_1_D
I0418 18:17:00.411756 24121 net.cpp:410] upsample1 <- pool1_mask
I0418 18:17:00.411768 24121 net.cpp:368] upsample1 -> pool1_D
I0418 18:17:00.411783 24121 net.cpp:120] Setting up upsample1
I0418 18:17:00.411795 24121 upsample_layer.cpp:31] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0418 18:17:00.411810 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:17:00.411823 24121 layer_factory.hpp:74] Creating layer conv1_2_D
I0418 18:17:00.411841 24121 net.cpp:90] Creating Layer conv1_2_D
I0418 18:17:00.411855 24121 net.cpp:410] conv1_2_D <- pool1_D
I0418 18:17:00.411873 24121 net.cpp:368] conv1_2_D -> conv1_2_D
I0418 18:17:00.411890 24121 net.cpp:120] Setting up conv1_2_D
I0418 18:17:00.420476 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:17:00.420498 24121 layer_factory.hpp:74] Creating layer conv1_2_D_bn
I0418 18:17:00.420519 24121 net.cpp:90] Creating Layer conv1_2_D_bn
I0418 18:17:00.420538 24121 net.cpp:410] conv1_2_D_bn <- conv1_2_D
I0418 18:17:00.420554 24121 net.cpp:357] conv1_2_D_bn -> conv1_2_D (in-place)
I0418 18:17:00.420572 24121 net.cpp:120] Setting up conv1_2_D_bn
I0418 18:17:00.421464 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:17:00.421484 24121 layer_factory.hpp:74] Creating layer relu1_2_D
I0418 18:17:00.421502 24121 net.cpp:90] Creating Layer relu1_2_D
I0418 18:17:00.421519 24121 net.cpp:410] relu1_2_D <- conv1_2_D
I0418 18:17:00.421531 24121 net.cpp:357] relu1_2_D -> conv1_2_D (in-place)
I0418 18:17:00.421550 24121 net.cpp:120] Setting up relu1_2_D
I0418 18:17:00.425050 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:17:00.425065 24121 layer_factory.hpp:74] Creating layer conv1_1_D
I0418 18:17:00.425082 24121 net.cpp:90] Creating Layer conv1_1_D
I0418 18:17:00.425092 24121 net.cpp:410] conv1_1_D <- conv1_2_D
I0418 18:17:00.425108 24121 net.cpp:368] conv1_1_D -> conv1_1_D
I0418 18:17:00.425123 24121 net.cpp:120] Setting up conv1_1_D
I0418 18:17:00.434476 24121 net.cpp:127] Top shape: 2 21 500 500 (10500000)
I0418 18:17:00.434499 24121 layer_factory.hpp:74] Creating layer conv1_1_D_conv1_1_D_0_split
I0418 18:17:00.434514 24121 net.cpp:90] Creating Layer conv1_1_D_conv1_1_D_0_split
I0418 18:17:00.434522 24121 net.cpp:410] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0418 18:17:00.434540 24121 net.cpp:368] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0418 18:17:00.434554 24121 net.cpp:368] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0418 18:17:00.434573 24121 net.cpp:120] Setting up conv1_1_D_conv1_1_D_0_split
I0418 18:17:00.434588 24121 net.cpp:127] Top shape: 2 21 500 500 (10500000)
I0418 18:17:00.434603 24121 net.cpp:127] Top shape: 2 21 500 500 (10500000)
I0418 18:17:00.434613 24121 layer_factory.hpp:74] Creating layer loss
I0418 18:17:00.434638 24121 net.cpp:90] Creating Layer loss
I0418 18:17:00.434653 24121 net.cpp:410] loss <- conv1_1_D_conv1_1_D_0_split_0
I0418 18:17:00.434664 24121 net.cpp:410] loss <- label_label_0_split_0
I0418 18:17:00.434680 24121 net.cpp:368] loss -> loss
I0418 18:17:00.434701 24121 net.cpp:120] Setting up loss
I0418 18:17:00.434722 24121 layer_factory.hpp:74] Creating layer loss
I0418 18:17:00.450258 24121 net.cpp:127] Top shape: (1)
I0418 18:17:00.450301 24121 net.cpp:129]     with loss weight 1
I0418 18:17:00.450340 24121 layer_factory.hpp:74] Creating layer accuracy
I0418 18:17:00.450361 24121 net.cpp:90] Creating Layer accuracy
I0418 18:17:00.450402 24121 net.cpp:410] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0418 18:17:00.450428 24121 net.cpp:410] accuracy <- label_label_0_split_1
I0418 18:17:00.450448 24121 net.cpp:368] accuracy -> accuracy
I0418 18:17:00.450469 24121 net.cpp:368] accuracy -> per_class_accuracy
I0418 18:17:00.450485 24121 net.cpp:120] Setting up accuracy
I0418 18:17:00.450508 24121 accuracy_layer.cpp:24] Per-class accuracies currently only work on TRAIN phase only.
I0418 18:17:00.450526 24121 net.cpp:127] Top shape: (1)
I0418 18:17:00.450538 24121 net.cpp:127] Top shape: 21 1 1 1 (21)
I0418 18:17:00.450548 24121 net.cpp:194] accuracy does not need backward computation.
I0418 18:17:00.450558 24121 net.cpp:192] loss needs backward computation.
I0418 18:17:00.450568 24121 net.cpp:192] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0418 18:17:00.450577 24121 net.cpp:192] conv1_1_D needs backward computation.
I0418 18:17:00.450587 24121 net.cpp:192] relu1_2_D needs backward computation.
I0418 18:17:00.450597 24121 net.cpp:192] conv1_2_D_bn needs backward computation.
I0418 18:17:00.450604 24121 net.cpp:192] conv1_2_D needs backward computation.
I0418 18:17:00.450613 24121 net.cpp:192] upsample1 needs backward computation.
I0418 18:17:00.450623 24121 net.cpp:192] upsample1_drop needs backward computation.
I0418 18:17:00.450633 24121 net.cpp:192] relu2_1_D needs backward computation.
I0418 18:17:00.450641 24121 net.cpp:192] conv2_1_D_bn needs backward computation.
I0418 18:17:00.450649 24121 net.cpp:192] conv2_1_D needs backward computation.
I0418 18:17:00.450659 24121 net.cpp:192] relu2_2_D needs backward computation.
I0418 18:17:00.450667 24121 net.cpp:192] conv2_2_D_bn needs backward computation.
I0418 18:17:00.450675 24121 net.cpp:192] conv2_2_D needs backward computation.
I0418 18:17:00.450685 24121 net.cpp:192] upsample2 needs backward computation.
I0418 18:17:00.450695 24121 net.cpp:192] upsample2_drop needs backward computation.
I0418 18:17:00.450703 24121 net.cpp:192] relu3_1_D needs backward computation.
I0418 18:17:00.450711 24121 net.cpp:192] conv3_1_D_bn needs backward computation.
I0418 18:17:00.450721 24121 net.cpp:192] conv3_1_D needs backward computation.
I0418 18:17:00.450729 24121 net.cpp:192] relu3_2_D needs backward computation.
I0418 18:17:00.450737 24121 net.cpp:192] conv3_2_D_bn needs backward computation.
I0418 18:17:00.450747 24121 net.cpp:192] conv3_2_D needs backward computation.
I0418 18:17:00.450755 24121 net.cpp:192] relu3_3_D needs backward computation.
I0418 18:17:00.450764 24121 net.cpp:192] conv3_3_D_bn needs backward computation.
I0418 18:17:00.450773 24121 net.cpp:192] conv3_3_D needs backward computation.
I0418 18:17:00.450781 24121 net.cpp:192] upsample3 needs backward computation.
I0418 18:17:00.450791 24121 net.cpp:192] upsample3_drop needs backward computation.
I0418 18:17:00.450800 24121 net.cpp:192] relu4_1_D needs backward computation.
I0418 18:17:00.450809 24121 net.cpp:192] conv4_1_D_bn needs backward computation.
I0418 18:17:00.450817 24121 net.cpp:192] conv4_1_D needs backward computation.
I0418 18:17:00.450826 24121 net.cpp:192] relu4_2_D needs backward computation.
I0418 18:17:00.450835 24121 net.cpp:192] conv4_2_D_bn needs backward computation.
I0418 18:17:00.450844 24121 net.cpp:192] conv4_2_D needs backward computation.
I0418 18:17:00.450853 24121 net.cpp:192] relu4_3_D needs backward computation.
I0418 18:17:00.450861 24121 net.cpp:192] conv4_3_D_bn needs backward computation.
I0418 18:17:00.450870 24121 net.cpp:192] conv4_3_D needs backward computation.
I0418 18:17:00.450880 24121 net.cpp:192] upsample4 needs backward computation.
I0418 18:17:00.450889 24121 net.cpp:192] upsample4_drop needs backward computation.
I0418 18:17:00.450898 24121 net.cpp:192] relu5_1_D needs backward computation.
I0418 18:17:00.450906 24121 net.cpp:192] conv5_1_D_bn needs backward computation.
I0418 18:17:00.450916 24121 net.cpp:192] conv5_1_D needs backward computation.
I0418 18:17:00.450924 24121 net.cpp:192] relu5_2_D needs backward computation.
I0418 18:17:00.450944 24121 net.cpp:192] conv5_2_D_bn needs backward computation.
I0418 18:17:00.450963 24121 net.cpp:192] conv5_2_D needs backward computation.
I0418 18:17:00.450973 24121 net.cpp:192] relu5_3_D needs backward computation.
I0418 18:17:00.450981 24121 net.cpp:192] conv5_3_D_bn needs backward computation.
I0418 18:17:00.450990 24121 net.cpp:192] conv5_3_D needs backward computation.
I0418 18:17:00.450999 24121 net.cpp:192] upsample5 needs backward computation.
I0418 18:17:00.451009 24121 net.cpp:192] upsample5_drop needs backward computation.
I0418 18:17:00.451019 24121 net.cpp:192] pool5 needs backward computation.
I0418 18:17:00.451027 24121 net.cpp:192] pool5_drop needs backward computation.
I0418 18:17:00.451036 24121 net.cpp:192] relu5_3 needs backward computation.
I0418 18:17:00.451045 24121 net.cpp:192] conv5_3_bn needs backward computation.
I0418 18:17:00.451053 24121 net.cpp:192] conv5_3 needs backward computation.
I0418 18:17:00.451063 24121 net.cpp:192] relu5_2 needs backward computation.
I0418 18:17:00.451071 24121 net.cpp:192] conv5_2_bn needs backward computation.
I0418 18:17:00.451081 24121 net.cpp:192] conv5_2 needs backward computation.
I0418 18:17:00.451089 24121 net.cpp:192] relu5_1 needs backward computation.
I0418 18:17:00.451098 24121 net.cpp:192] conv5_1_bn needs backward computation.
I0418 18:17:00.451107 24121 net.cpp:192] conv5_1 needs backward computation.
I0418 18:17:00.451125 24121 net.cpp:192] pool4 needs backward computation.
I0418 18:17:00.451134 24121 net.cpp:192] pool4_drop needs backward computation.
I0418 18:17:00.451143 24121 net.cpp:192] relu4_3 needs backward computation.
I0418 18:17:00.451151 24121 net.cpp:192] conv4_3_bn needs backward computation.
I0418 18:17:00.451160 24121 net.cpp:192] conv4_3 needs backward computation.
I0418 18:17:00.451169 24121 net.cpp:192] relu4_2 needs backward computation.
I0418 18:17:00.451179 24121 net.cpp:192] conv4_2_bn needs backward computation.
I0418 18:17:00.451186 24121 net.cpp:192] conv4_2 needs backward computation.
I0418 18:17:00.451195 24121 net.cpp:192] relu4_1 needs backward computation.
I0418 18:17:00.451205 24121 net.cpp:192] conv4_1_bn needs backward computation.
I0418 18:17:00.451212 24121 net.cpp:192] conv4_1 needs backward computation.
I0418 18:17:00.451222 24121 net.cpp:192] pool3 needs backward computation.
I0418 18:17:00.451231 24121 net.cpp:192] pool3_drop needs backward computation.
I0418 18:17:00.451241 24121 net.cpp:192] relu3_3 needs backward computation.
I0418 18:17:00.451249 24121 net.cpp:192] conv3_3_bn needs backward computation.
I0418 18:17:00.451257 24121 net.cpp:192] conv3_3 needs backward computation.
I0418 18:17:00.451267 24121 net.cpp:192] relu3_2 needs backward computation.
I0418 18:17:00.451275 24121 net.cpp:192] conv3_2_bn needs backward computation.
I0418 18:17:00.451284 24121 net.cpp:192] conv3_2 needs backward computation.
I0418 18:17:00.451293 24121 net.cpp:192] relu3_1 needs backward computation.
I0418 18:17:00.451302 24121 net.cpp:192] conv3_1_bn needs backward computation.
I0418 18:17:00.451310 24121 net.cpp:192] conv3_1 needs backward computation.
I0418 18:17:00.451319 24121 net.cpp:192] pool2 needs backward computation.
I0418 18:17:00.451329 24121 net.cpp:192] pool2_drop needs backward computation.
I0418 18:17:00.451338 24121 net.cpp:192] relu2_2 needs backward computation.
I0418 18:17:00.451346 24121 net.cpp:192] conv2_2_bn needs backward computation.
I0418 18:17:00.451354 24121 net.cpp:192] conv2_2 needs backward computation.
I0418 18:17:00.451364 24121 net.cpp:192] relu2_1 needs backward computation.
I0418 18:17:00.451372 24121 net.cpp:192] conv2_1_bn needs backward computation.
I0418 18:17:00.451380 24121 net.cpp:192] conv2_1 needs backward computation.
I0418 18:17:00.451390 24121 net.cpp:192] pool1 needs backward computation.
I0418 18:17:00.451400 24121 net.cpp:192] pool1_drop needs backward computation.
I0418 18:17:00.451407 24121 net.cpp:192] relu1_2 needs backward computation.
I0418 18:17:00.451416 24121 net.cpp:192] conv1_2_bn needs backward computation.
I0418 18:17:00.451424 24121 net.cpp:192] conv1_2 needs backward computation.
I0418 18:17:00.451448 24121 net.cpp:192] relu1_1 needs backward computation.
I0418 18:17:00.451458 24121 net.cpp:192] conv1_1_bn needs backward computation.
I0418 18:17:00.451467 24121 net.cpp:192] conv1_1 needs backward computation.
I0418 18:17:00.451478 24121 net.cpp:194] label_label_0_split does not need backward computation.
I0418 18:17:00.451488 24121 net.cpp:194] label does not need backward computation.
I0418 18:17:00.451496 24121 net.cpp:194] data does not need backward computation.
I0418 18:17:00.451504 24121 net.cpp:235] This network produces output accuracy
I0418 18:17:00.451513 24121 net.cpp:235] This network produces output loss
I0418 18:17:00.451522 24121 net.cpp:235] This network produces output per_class_accuracy
I0418 18:17:00.451581 24121 net.cpp:482] Collecting Learning Rate and Weight Decay.
I0418 18:17:00.451617 24121 net.cpp:247] Network initialization done.
I0418 18:17:00.451628 24121 net.cpp:248] Memory required for data: 3506755292
I0418 18:17:00.453974 24121 solver.cpp:154] Creating test net (#0) specified by net file: /home/pierre/hgRepos/models/caffeSegNet/train_segnet-pascal_lmdb/dropout_weighting/train_val.prototxt
I0418 18:17:00.454112 24121 net.cpp:287] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0418 18:17:00.454128 24121 net.cpp:287] The NetState phase (1) differed from the phase (0) specified by a rule in layer label
I0418 18:17:00.454926 24121 net.cpp:42] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layer"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 104.00699
    mean_value: 116.66877
    mean_value: 122.67892
  }
  data_param {
    source: "/home/shared/datasets/VOCdevkit/VOC2012/LMDB/val_lmdb"
    batch_size: 2
    backend: LMDB
  }
}
layer {
  name: "label"
  type: "Data"
  top: "label"
  include {
    phase: TEST
  }
  data_param {
    source: "/home/shared/datasets/VOCdevkit/VOC2012/LMDB/val_gt_lmdb"
    batch_size: 2
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_1_bn"
  type: "BN"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_2_bn"
  type: "BN"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1_drop"
  type: "Dropout"
  bottom: "conv1_2"
  top: "conv1_2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_bn"
  type: "BN"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2_bn"
  type: "BN"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2_drop"
  type: "Dropout"
  bottom: "conv2_2"
  top: "conv2_2"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn"
  type: "BN"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2_bn"
  type: "BN"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3_bn"
  type: "BN"
  bottom: "conv3_3"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3_drop"
  type: "Dropout"
  bottom: "conv3_3"
  top: "conv3_3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn"
  type: "BN"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2_bn"
  type: "BN"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_bn"
  type: "BN"
  bottom: "conv4_3"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4_drop"
  type: "Dropout"
  bottom: "conv4_3"
  top: "conv4_3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BN"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5_2_bn"
  type: "BN"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5_3_bn"
  type: "BN"
  bottom: "conv5_3"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5_drop"
  type: "Dropout"
  bottom: "conv5_3"
  top: "conv5_3"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5_drop"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 32
    upsample_w: 32
  }
}
layer {
  name: "conv5_3_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5_3_D_bn"
  type: "BN"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_3_D"
  type: "ReLU"
  bottom: "conv5_3_D"
  top: "conv5_3_D"
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "conv5_3_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5_2_D_bn"
  type: "BN"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5_1_D_bn"
  type: "BN"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4_drop"
  type: "Dropout"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 63
    upsample_w: 63
  }
}
layer {
  name: "conv4_3_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_D_bn"
  type: "BN"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3_D"
  type: "ReLU"
  bottom: "conv4_3_D"
  top: "conv4_3_D"
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "conv4_3_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2_D_bn"
  type: "BN"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_D_bn"
  type: "BN"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3_drop"
  type: "Dropout"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 125
    upsample_w: 125
  }
}
layer {
  name: "conv3_3_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3_D_bn"
  type: "BN"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3_D"
  type: "ReLU"
  bottom: "conv3_3_D"
  top: "conv3_3_D"
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "conv3_3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2_D_bn"
  type: "BN"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_D_bn"
  type: "BN"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2_drop"
  type: "Dropout"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2_D_bn"
  type: "BN"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_D_bn"
  type: "BN"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1_drop"
  type: "Dropout"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_2_D_bn"
  type: "BN"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  bn_param {
    scale_filler {
      type: "constant"
      value: 1
    }
    shift_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
  loss_param {
    ignore_label: 21
    weight_by_label_freqs: true
    class_weighting: 0.2719
    class_weighting: 1.583
    class_weighting: 3.012
    class_weighting: 1.6572
    class_weighting: 1.7892
    class_weighting: 1.7815
    class_weighting: 0.5962
    class_weighting: 1.2053
    class_weighting: 0.674
    class_weighting: 1.8299
    class_weighting: 0.9166
    class_weighting: 0.8532
    class_weighting: 0.8935
    class_weighting: 0.9973
    class_weighting: 0.9742
    class_weighting: 1.1778
    class_weighting: 1.9162
    class_weighting: 1
    class_weighting: 0.8758
    class_weighting: 0.7225
    class_weighting: 1.3287
  }
  softmax_param {
    engine: CAFFE
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
  top: "per_class_accuracy"
}
I0418 18:17:00.455518 24121 layer_factory.hpp:74] Creating layer data
I0418 18:17:00.455538 24121 net.cpp:90] Creating Layer data
I0418 18:17:00.455549 24121 net.cpp:368] data -> data
I0418 18:17:00.455564 24121 net.cpp:120] Setting up data
I0418 18:17:00.455639 24121 db.cpp:34] Opened lmdb /home/shared/datasets/VOCdevkit/VOC2012/LMDB/val_lmdb
I0418 18:17:00.456599 24121 data_layer.cpp:52] output data size: 2,3,500,500
I0418 18:17:00.458372 24121 net.cpp:127] Top shape: 2 3 500 500 (1500000)
I0418 18:17:00.458395 24121 layer_factory.hpp:74] Creating layer label
I0418 18:17:00.458415 24121 net.cpp:90] Creating Layer label
I0418 18:17:00.458427 24121 net.cpp:368] label -> label
I0418 18:17:00.458446 24121 net.cpp:120] Setting up label
I0418 18:17:00.458529 24121 db.cpp:34] Opened lmdb /home/shared/datasets/VOCdevkit/VOC2012/LMDB/val_gt_lmdb
I0418 18:17:00.458951 24121 data_layer.cpp:52] output data size: 2,1,500,500
I0418 18:17:00.459842 24121 net.cpp:127] Top shape: 2 1 500 500 (500000)
I0418 18:17:00.459861 24121 layer_factory.hpp:74] Creating layer label_label_0_split
I0418 18:17:00.459879 24121 net.cpp:90] Creating Layer label_label_0_split
I0418 18:17:00.459889 24121 net.cpp:410] label_label_0_split <- label
I0418 18:17:00.459903 24121 net.cpp:368] label_label_0_split -> label_label_0_split_0
I0418 18:17:00.459919 24121 net.cpp:368] label_label_0_split -> label_label_0_split_1
I0418 18:17:00.459931 24121 net.cpp:120] Setting up label_label_0_split
I0418 18:17:00.459945 24121 net.cpp:127] Top shape: 2 1 500 500 (500000)
I0418 18:17:00.459957 24121 net.cpp:127] Top shape: 2 1 500 500 (500000)
I0418 18:17:00.459966 24121 layer_factory.hpp:74] Creating layer conv1_1
I0418 18:17:00.459982 24121 net.cpp:90] Creating Layer conv1_1
I0418 18:17:00.459991 24121 net.cpp:410] conv1_1 <- data
I0418 18:17:00.460003 24121 net.cpp:368] conv1_1 -> conv1_1
I0418 18:17:00.460018 24121 net.cpp:120] Setting up conv1_1
I0418 18:17:00.467758 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:17:00.467794 24121 layer_factory.hpp:74] Creating layer conv1_1_bn
I0418 18:17:00.467823 24121 net.cpp:90] Creating Layer conv1_1_bn
I0418 18:17:00.467835 24121 net.cpp:410] conv1_1_bn <- conv1_1
I0418 18:17:00.467851 24121 net.cpp:357] conv1_1_bn -> conv1_1 (in-place)
I0418 18:17:00.467876 24121 net.cpp:120] Setting up conv1_1_bn
I0418 18:17:00.468739 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:17:00.468760 24121 layer_factory.hpp:74] Creating layer relu1_1
I0418 18:17:00.468777 24121 net.cpp:90] Creating Layer relu1_1
I0418 18:17:00.468787 24121 net.cpp:410] relu1_1 <- conv1_1
I0418 18:17:00.468802 24121 net.cpp:357] relu1_1 -> conv1_1 (in-place)
I0418 18:17:00.468822 24121 net.cpp:120] Setting up relu1_1
I0418 18:17:00.470945 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:17:00.470959 24121 layer_factory.hpp:74] Creating layer conv1_2
I0418 18:17:00.470978 24121 net.cpp:90] Creating Layer conv1_2
I0418 18:17:00.471016 24121 net.cpp:410] conv1_2 <- conv1_1
I0418 18:17:00.471035 24121 net.cpp:368] conv1_2 -> conv1_2
I0418 18:17:00.471053 24121 net.cpp:120] Setting up conv1_2
I0418 18:17:00.478837 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:17:00.478863 24121 layer_factory.hpp:74] Creating layer conv1_2_bn
I0418 18:17:00.478886 24121 net.cpp:90] Creating Layer conv1_2_bn
I0418 18:17:00.478900 24121 net.cpp:410] conv1_2_bn <- conv1_2
I0418 18:17:00.478914 24121 net.cpp:357] conv1_2_bn -> conv1_2 (in-place)
I0418 18:17:00.478934 24121 net.cpp:120] Setting up conv1_2_bn
I0418 18:17:00.479842 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:17:00.479864 24121 layer_factory.hpp:74] Creating layer relu1_2
I0418 18:17:00.479881 24121 net.cpp:90] Creating Layer relu1_2
I0418 18:17:00.479893 24121 net.cpp:410] relu1_2 <- conv1_2
I0418 18:17:00.479908 24121 net.cpp:357] relu1_2 -> conv1_2 (in-place)
I0418 18:17:00.479921 24121 net.cpp:120] Setting up relu1_2
I0418 18:17:00.481851 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:17:00.481865 24121 layer_factory.hpp:74] Creating layer pool1_drop
I0418 18:17:00.481879 24121 net.cpp:90] Creating Layer pool1_drop
I0418 18:17:00.481887 24121 net.cpp:410] pool1_drop <- conv1_2
I0418 18:17:00.481905 24121 net.cpp:357] pool1_drop -> conv1_2 (in-place)
I0418 18:17:00.481920 24121 net.cpp:120] Setting up pool1_drop
I0418 18:17:00.481940 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:17:00.481955 24121 layer_factory.hpp:74] Creating layer pool1
I0418 18:17:00.481966 24121 layer_factory.cpp:55] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0418 18:17:00.481977 24121 net.cpp:90] Creating Layer pool1
I0418 18:17:00.481986 24121 net.cpp:410] pool1 <- conv1_2
I0418 18:17:00.482003 24121 net.cpp:368] pool1 -> pool1
I0418 18:17:00.482022 24121 net.cpp:368] pool1 -> pool1_mask
I0418 18:17:00.482039 24121 net.cpp:120] Setting up pool1
I0418 18:17:00.482060 24121 net.cpp:127] Top shape: 2 64 250 250 (8000000)
I0418 18:17:00.482076 24121 net.cpp:127] Top shape: 2 64 250 250 (8000000)
I0418 18:17:00.482086 24121 layer_factory.hpp:74] Creating layer conv2_1
I0418 18:17:00.482100 24121 net.cpp:90] Creating Layer conv2_1
I0418 18:17:00.482112 24121 net.cpp:410] conv2_1 <- pool1
I0418 18:17:00.482130 24121 net.cpp:368] conv2_1 -> conv2_1
I0418 18:17:00.482149 24121 net.cpp:120] Setting up conv2_1
I0418 18:17:00.489956 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:17:00.489979 24121 layer_factory.hpp:74] Creating layer conv2_1_bn
I0418 18:17:00.489998 24121 net.cpp:90] Creating Layer conv2_1_bn
I0418 18:17:00.490008 24121 net.cpp:410] conv2_1_bn <- conv2_1
I0418 18:17:00.490025 24121 net.cpp:357] conv2_1_bn -> conv2_1 (in-place)
I0418 18:17:00.490043 24121 net.cpp:120] Setting up conv2_1_bn
I0418 18:17:00.490291 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:17:00.490309 24121 layer_factory.hpp:74] Creating layer relu2_1
I0418 18:17:00.490325 24121 net.cpp:90] Creating Layer relu2_1
I0418 18:17:00.490339 24121 net.cpp:410] relu2_1 <- conv2_1
I0418 18:17:00.490351 24121 net.cpp:357] relu2_1 -> conv2_1 (in-place)
I0418 18:17:00.490370 24121 net.cpp:120] Setting up relu2_1
I0418 18:17:00.494146 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:17:00.494160 24121 layer_factory.hpp:74] Creating layer conv2_2
I0418 18:17:00.494174 24121 net.cpp:90] Creating Layer conv2_2
I0418 18:17:00.494184 24121 net.cpp:410] conv2_2 <- conv2_1
I0418 18:17:00.494204 24121 net.cpp:368] conv2_2 -> conv2_2
I0418 18:17:00.494225 24121 net.cpp:120] Setting up conv2_2
I0418 18:17:00.502645 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:17:00.502665 24121 layer_factory.hpp:74] Creating layer conv2_2_bn
I0418 18:17:00.502687 24121 net.cpp:90] Creating Layer conv2_2_bn
I0418 18:17:00.502697 24121 net.cpp:410] conv2_2_bn <- conv2_2
I0418 18:17:00.502712 24121 net.cpp:357] conv2_2_bn -> conv2_2 (in-place)
I0418 18:17:00.502732 24121 net.cpp:120] Setting up conv2_2_bn
I0418 18:17:00.502998 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:17:00.503016 24121 layer_factory.hpp:74] Creating layer relu2_2
I0418 18:17:00.503037 24121 net.cpp:90] Creating Layer relu2_2
I0418 18:17:00.503053 24121 net.cpp:410] relu2_2 <- conv2_2
I0418 18:17:00.503067 24121 net.cpp:357] relu2_2 -> conv2_2 (in-place)
I0418 18:17:00.503084 24121 net.cpp:120] Setting up relu2_2
I0418 18:17:00.506891 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:17:00.506906 24121 layer_factory.hpp:74] Creating layer pool2_drop
I0418 18:17:00.506922 24121 net.cpp:90] Creating Layer pool2_drop
I0418 18:17:00.506935 24121 net.cpp:410] pool2_drop <- conv2_2
I0418 18:17:00.506947 24121 net.cpp:357] pool2_drop -> conv2_2 (in-place)
I0418 18:17:00.506959 24121 net.cpp:120] Setting up pool2_drop
I0418 18:17:00.506974 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:17:00.506984 24121 layer_factory.hpp:74] Creating layer pool2
I0418 18:17:00.506994 24121 layer_factory.cpp:55] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0418 18:17:00.507007 24121 net.cpp:90] Creating Layer pool2
I0418 18:17:00.507025 24121 net.cpp:410] pool2 <- conv2_2
I0418 18:17:00.507037 24121 net.cpp:368] pool2 -> pool2
I0418 18:17:00.507052 24121 net.cpp:368] pool2 -> pool2_mask
I0418 18:17:00.507067 24121 net.cpp:120] Setting up pool2
I0418 18:17:00.507083 24121 net.cpp:127] Top shape: 2 128 125 125 (4000000)
I0418 18:17:00.507097 24121 net.cpp:127] Top shape: 2 128 125 125 (4000000)
I0418 18:17:00.507107 24121 layer_factory.hpp:74] Creating layer conv3_1
I0418 18:17:00.507174 24121 net.cpp:90] Creating Layer conv3_1
I0418 18:17:00.507189 24121 net.cpp:410] conv3_1 <- pool2
I0418 18:17:00.507206 24121 net.cpp:368] conv3_1 -> conv3_1
I0418 18:17:00.507225 24121 net.cpp:120] Setting up conv3_1
I0418 18:17:00.515076 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:00.515101 24121 layer_factory.hpp:74] Creating layer conv3_1_bn
I0418 18:17:00.515224 24121 net.cpp:90] Creating Layer conv3_1_bn
I0418 18:17:00.515242 24121 net.cpp:410] conv3_1_bn <- conv3_1
I0418 18:17:00.515259 24121 net.cpp:357] conv3_1_bn -> conv3_1 (in-place)
I0418 18:17:00.515277 24121 net.cpp:120] Setting up conv3_1_bn
I0418 18:17:00.515369 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:00.515391 24121 layer_factory.hpp:74] Creating layer relu3_1
I0418 18:17:00.515404 24121 net.cpp:90] Creating Layer relu3_1
I0418 18:17:00.515418 24121 net.cpp:410] relu3_1 <- conv3_1
I0418 18:17:00.515432 24121 net.cpp:357] relu3_1 -> conv3_1 (in-place)
I0418 18:17:00.515450 24121 net.cpp:120] Setting up relu3_1
I0418 18:17:00.519336 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:00.519351 24121 layer_factory.hpp:74] Creating layer conv3_2
I0418 18:17:00.519367 24121 net.cpp:90] Creating Layer conv3_2
I0418 18:17:00.519381 24121 net.cpp:410] conv3_2 <- conv3_1
I0418 18:17:00.519394 24121 net.cpp:368] conv3_2 -> conv3_2
I0418 18:17:00.519409 24121 net.cpp:120] Setting up conv3_2
I0418 18:17:00.531371 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:00.531393 24121 layer_factory.hpp:74] Creating layer conv3_2_bn
I0418 18:17:00.531414 24121 net.cpp:90] Creating Layer conv3_2_bn
I0418 18:17:00.531424 24121 net.cpp:410] conv3_2_bn <- conv3_2
I0418 18:17:00.531441 24121 net.cpp:357] conv3_2_bn -> conv3_2 (in-place)
I0418 18:17:00.531461 24121 net.cpp:120] Setting up conv3_2_bn
I0418 18:17:00.531551 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:00.531570 24121 layer_factory.hpp:74] Creating layer relu3_2
I0418 18:17:00.531590 24121 net.cpp:90] Creating Layer relu3_2
I0418 18:17:00.531605 24121 net.cpp:410] relu3_2 <- conv3_2
I0418 18:17:00.531621 24121 net.cpp:357] relu3_2 -> conv3_2 (in-place)
I0418 18:17:00.531640 24121 net.cpp:120] Setting up relu3_2
I0418 18:17:00.533818 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:00.533831 24121 layer_factory.hpp:74] Creating layer conv3_3
I0418 18:17:00.533845 24121 net.cpp:90] Creating Layer conv3_3
I0418 18:17:00.533882 24121 net.cpp:410] conv3_3 <- conv3_2
I0418 18:17:00.533901 24121 net.cpp:368] conv3_3 -> conv3_3
I0418 18:17:00.533918 24121 net.cpp:120] Setting up conv3_3
I0418 18:17:00.543668 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:00.543690 24121 layer_factory.hpp:74] Creating layer conv3_3_bn
I0418 18:17:00.543712 24121 net.cpp:90] Creating Layer conv3_3_bn
I0418 18:17:00.543722 24121 net.cpp:410] conv3_3_bn <- conv3_3
I0418 18:17:00.543738 24121 net.cpp:357] conv3_3_bn -> conv3_3 (in-place)
I0418 18:17:00.543753 24121 net.cpp:120] Setting up conv3_3_bn
I0418 18:17:00.543841 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:00.543860 24121 layer_factory.hpp:74] Creating layer relu3_3
I0418 18:17:00.543876 24121 net.cpp:90] Creating Layer relu3_3
I0418 18:17:00.543886 24121 net.cpp:410] relu3_3 <- conv3_3
I0418 18:17:00.543900 24121 net.cpp:357] relu3_3 -> conv3_3 (in-place)
I0418 18:17:00.543917 24121 net.cpp:120] Setting up relu3_3
I0418 18:17:00.546775 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:00.546789 24121 layer_factory.hpp:74] Creating layer pool3_drop
I0418 18:17:00.546805 24121 net.cpp:90] Creating Layer pool3_drop
I0418 18:17:00.546818 24121 net.cpp:410] pool3_drop <- conv3_3
I0418 18:17:00.546830 24121 net.cpp:357] pool3_drop -> conv3_3 (in-place)
I0418 18:17:00.546846 24121 net.cpp:120] Setting up pool3_drop
I0418 18:17:00.546860 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:00.546875 24121 layer_factory.hpp:74] Creating layer pool3
I0418 18:17:00.546885 24121 layer_factory.cpp:55] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0418 18:17:00.546896 24121 net.cpp:90] Creating Layer pool3
I0418 18:17:00.546905 24121 net.cpp:410] pool3 <- conv3_3
I0418 18:17:00.546918 24121 net.cpp:368] pool3 -> pool3
I0418 18:17:00.546932 24121 net.cpp:368] pool3 -> pool3_mask
I0418 18:17:00.546952 24121 net.cpp:120] Setting up pool3
I0418 18:17:00.546972 24121 net.cpp:127] Top shape: 2 256 63 63 (2032128)
I0418 18:17:00.546986 24121 net.cpp:127] Top shape: 2 256 63 63 (2032128)
I0418 18:17:00.546996 24121 layer_factory.hpp:74] Creating layer conv4_1
I0418 18:17:00.547013 24121 net.cpp:90] Creating Layer conv4_1
I0418 18:17:00.547024 24121 net.cpp:410] conv4_1 <- pool3
I0418 18:17:00.547040 24121 net.cpp:368] conv4_1 -> conv4_1
I0418 18:17:00.547057 24121 net.cpp:120] Setting up conv4_1
I0418 18:17:00.560014 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.560047 24121 layer_factory.hpp:74] Creating layer conv4_1_bn
I0418 18:17:00.560067 24121 net.cpp:90] Creating Layer conv4_1_bn
I0418 18:17:00.560084 24121 net.cpp:410] conv4_1_bn <- conv4_1
I0418 18:17:00.560098 24121 net.cpp:357] conv4_1_bn -> conv4_1 (in-place)
I0418 18:17:00.560114 24121 net.cpp:120] Setting up conv4_1_bn
I0418 18:17:00.560166 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.560184 24121 layer_factory.hpp:74] Creating layer relu4_1
I0418 18:17:00.560205 24121 net.cpp:90] Creating Layer relu4_1
I0418 18:17:00.560219 24121 net.cpp:410] relu4_1 <- conv4_1
I0418 18:17:00.560235 24121 net.cpp:357] relu4_1 -> conv4_1 (in-place)
I0418 18:17:00.560247 24121 net.cpp:120] Setting up relu4_1
I0418 18:17:00.563863 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.563876 24121 layer_factory.hpp:74] Creating layer conv4_2
I0418 18:17:00.563895 24121 net.cpp:90] Creating Layer conv4_2
I0418 18:17:00.563910 24121 net.cpp:410] conv4_2 <- conv4_1
I0418 18:17:00.563925 24121 net.cpp:368] conv4_2 -> conv4_2
I0418 18:17:00.563947 24121 net.cpp:120] Setting up conv4_2
I0418 18:17:00.586117 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.586174 24121 layer_factory.hpp:74] Creating layer conv4_2_bn
I0418 18:17:00.586201 24121 net.cpp:90] Creating Layer conv4_2_bn
I0418 18:17:00.586213 24121 net.cpp:410] conv4_2_bn <- conv4_2
I0418 18:17:00.586230 24121 net.cpp:357] conv4_2_bn -> conv4_2 (in-place)
I0418 18:17:00.586247 24121 net.cpp:120] Setting up conv4_2_bn
I0418 18:17:00.586313 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.586331 24121 layer_factory.hpp:74] Creating layer relu4_2
I0418 18:17:00.586349 24121 net.cpp:90] Creating Layer relu4_2
I0418 18:17:00.586364 24121 net.cpp:410] relu4_2 <- conv4_2
I0418 18:17:00.586377 24121 net.cpp:357] relu4_2 -> conv4_2 (in-place)
I0418 18:17:00.586390 24121 net.cpp:120] Setting up relu4_2
I0418 18:17:00.587528 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.587543 24121 layer_factory.hpp:74] Creating layer conv4_3
I0418 18:17:00.587558 24121 net.cpp:90] Creating Layer conv4_3
I0418 18:17:00.587568 24121 net.cpp:410] conv4_3 <- conv4_2
I0418 18:17:00.587587 24121 net.cpp:368] conv4_3 -> conv4_3
I0418 18:17:00.587609 24121 net.cpp:120] Setting up conv4_3
I0418 18:17:00.706537 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.706580 24121 layer_factory.hpp:74] Creating layer conv4_3_bn
I0418 18:17:00.706603 24121 net.cpp:90] Creating Layer conv4_3_bn
I0418 18:17:00.706614 24121 net.cpp:410] conv4_3_bn <- conv4_3
I0418 18:17:00.706632 24121 net.cpp:357] conv4_3_bn -> conv4_3 (in-place)
I0418 18:17:00.706650 24121 net.cpp:120] Setting up conv4_3_bn
I0418 18:17:00.706699 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.706717 24121 layer_factory.hpp:74] Creating layer relu4_3
I0418 18:17:00.706732 24121 net.cpp:90] Creating Layer relu4_3
I0418 18:17:00.706746 24121 net.cpp:410] relu4_3 <- conv4_3
I0418 18:17:00.706763 24121 net.cpp:357] relu4_3 -> conv4_3 (in-place)
I0418 18:17:00.706779 24121 net.cpp:120] Setting up relu4_3
I0418 18:17:00.707855 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.707871 24121 layer_factory.hpp:74] Creating layer pool4_drop
I0418 18:17:00.707888 24121 net.cpp:90] Creating Layer pool4_drop
I0418 18:17:00.707898 24121 net.cpp:410] pool4_drop <- conv4_3
I0418 18:17:00.707911 24121 net.cpp:357] pool4_drop -> conv4_3 (in-place)
I0418 18:17:00.707923 24121 net.cpp:120] Setting up pool4_drop
I0418 18:17:00.707938 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:00.707957 24121 layer_factory.hpp:74] Creating layer pool4
I0418 18:17:00.707967 24121 layer_factory.cpp:55] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0418 18:17:00.707979 24121 net.cpp:90] Creating Layer pool4
I0418 18:17:00.707988 24121 net.cpp:410] pool4 <- conv4_3
I0418 18:17:00.708005 24121 net.cpp:368] pool4 -> pool4
I0418 18:17:00.708024 24121 net.cpp:368] pool4 -> pool4_mask
I0418 18:17:00.708039 24121 net.cpp:120] Setting up pool4
I0418 18:17:00.708058 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.708076 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.708086 24121 layer_factory.hpp:74] Creating layer conv5_1
I0418 18:17:00.708103 24121 net.cpp:90] Creating Layer conv5_1
I0418 18:17:00.708117 24121 net.cpp:410] conv5_1 <- pool4
I0418 18:17:00.708132 24121 net.cpp:368] conv5_1 -> conv5_1
I0418 18:17:00.708147 24121 net.cpp:120] Setting up conv5_1
I0418 18:17:00.728672 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.728718 24121 layer_factory.hpp:74] Creating layer conv5_1_bn
I0418 18:17:00.728741 24121 net.cpp:90] Creating Layer conv5_1_bn
I0418 18:17:00.728755 24121 net.cpp:410] conv5_1_bn <- conv5_1
I0418 18:17:00.728771 24121 net.cpp:357] conv5_1_bn -> conv5_1 (in-place)
I0418 18:17:00.728788 24121 net.cpp:120] Setting up conv5_1_bn
I0418 18:17:00.728826 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.728847 24121 layer_factory.hpp:74] Creating layer relu5_1
I0418 18:17:00.728868 24121 net.cpp:90] Creating Layer relu5_1
I0418 18:17:00.728883 24121 net.cpp:410] relu5_1 <- conv5_1
I0418 18:17:00.728896 24121 net.cpp:357] relu5_1 -> conv5_1 (in-place)
I0418 18:17:00.728909 24121 net.cpp:120] Setting up relu5_1
I0418 18:17:00.732671 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.732684 24121 layer_factory.hpp:74] Creating layer conv5_2
I0418 18:17:00.732702 24121 net.cpp:90] Creating Layer conv5_2
I0418 18:17:00.732743 24121 net.cpp:410] conv5_2 <- conv5_1
I0418 18:17:00.732758 24121 net.cpp:368] conv5_2 -> conv5_2
I0418 18:17:00.732779 24121 net.cpp:120] Setting up conv5_2
I0418 18:17:00.758582 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.758625 24121 layer_factory.hpp:74] Creating layer conv5_2_bn
I0418 18:17:00.758648 24121 net.cpp:90] Creating Layer conv5_2_bn
I0418 18:17:00.758662 24121 net.cpp:410] conv5_2_bn <- conv5_2
I0418 18:17:00.758676 24121 net.cpp:357] conv5_2_bn -> conv5_2 (in-place)
I0418 18:17:00.758692 24121 net.cpp:120] Setting up conv5_2_bn
I0418 18:17:00.758728 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.758750 24121 layer_factory.hpp:74] Creating layer relu5_2
I0418 18:17:00.758769 24121 net.cpp:90] Creating Layer relu5_2
I0418 18:17:00.758783 24121 net.cpp:410] relu5_2 <- conv5_2
I0418 18:17:00.758796 24121 net.cpp:357] relu5_2 -> conv5_2 (in-place)
I0418 18:17:00.758816 24121 net.cpp:120] Setting up relu5_2
I0418 18:17:00.764570 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.764585 24121 layer_factory.hpp:74] Creating layer conv5_3
I0418 18:17:00.764602 24121 net.cpp:90] Creating Layer conv5_3
I0418 18:17:00.764617 24121 net.cpp:410] conv5_3 <- conv5_2
I0418 18:17:00.764634 24121 net.cpp:368] conv5_3 -> conv5_3
I0418 18:17:00.764653 24121 net.cpp:120] Setting up conv5_3
I0418 18:17:00.880349 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.880390 24121 layer_factory.hpp:74] Creating layer conv5_3_bn
I0418 18:17:00.880414 24121 net.cpp:90] Creating Layer conv5_3_bn
I0418 18:17:00.880427 24121 net.cpp:410] conv5_3_bn <- conv5_3
I0418 18:17:00.880446 24121 net.cpp:357] conv5_3_bn -> conv5_3 (in-place)
I0418 18:17:00.880465 24121 net.cpp:120] Setting up conv5_3_bn
I0418 18:17:00.880511 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.880532 24121 layer_factory.hpp:74] Creating layer relu5_3
I0418 18:17:00.880548 24121 net.cpp:90] Creating Layer relu5_3
I0418 18:17:00.880563 24121 net.cpp:410] relu5_3 <- conv5_3
I0418 18:17:00.880574 24121 net.cpp:357] relu5_3 -> conv5_3 (in-place)
I0418 18:17:00.880594 24121 net.cpp:120] Setting up relu5_3
I0418 18:17:00.883287 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.883302 24121 layer_factory.hpp:74] Creating layer pool5_drop
I0418 18:17:00.883318 24121 net.cpp:90] Creating Layer pool5_drop
I0418 18:17:00.883332 24121 net.cpp:410] pool5_drop <- conv5_3
I0418 18:17:00.883344 24121 net.cpp:357] pool5_drop -> conv5_3 (in-place)
I0418 18:17:00.883361 24121 net.cpp:120] Setting up pool5_drop
I0418 18:17:00.883376 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.883388 24121 layer_factory.hpp:74] Creating layer pool5
I0418 18:17:00.883399 24121 layer_factory.cpp:55] CUDNN does not support padding or multiple tops. Using Caffe's own pooling layer.
I0418 18:17:00.883411 24121 net.cpp:90] Creating Layer pool5
I0418 18:17:00.883420 24121 net.cpp:410] pool5 <- conv5_3
I0418 18:17:00.883435 24121 net.cpp:368] pool5 -> pool5
I0418 18:17:00.883455 24121 net.cpp:368] pool5 -> pool5_mask
I0418 18:17:00.883472 24121 net.cpp:120] Setting up pool5
I0418 18:17:00.883494 24121 net.cpp:127] Top shape: 2 512 16 16 (262144)
I0418 18:17:00.883508 24121 net.cpp:127] Top shape: 2 512 16 16 (262144)
I0418 18:17:00.883518 24121 layer_factory.hpp:74] Creating layer upsample5_drop
I0418 18:17:00.883533 24121 net.cpp:90] Creating Layer upsample5_drop
I0418 18:17:00.883545 24121 net.cpp:410] upsample5_drop <- pool5
I0418 18:17:00.883558 24121 net.cpp:357] upsample5_drop -> pool5 (in-place)
I0418 18:17:00.883570 24121 net.cpp:120] Setting up upsample5_drop
I0418 18:17:00.883585 24121 net.cpp:127] Top shape: 2 512 16 16 (262144)
I0418 18:17:00.883597 24121 layer_factory.hpp:74] Creating layer upsample5
I0418 18:17:00.883613 24121 net.cpp:90] Creating Layer upsample5
I0418 18:17:00.883625 24121 net.cpp:410] upsample5 <- pool5
I0418 18:17:00.883637 24121 net.cpp:410] upsample5 <- pool5_mask
I0418 18:17:00.883651 24121 net.cpp:368] upsample5 -> pool5_D
I0418 18:17:00.883679 24121 net.cpp:120] Setting up upsample5
I0418 18:17:00.883697 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.883708 24121 layer_factory.hpp:74] Creating layer conv5_3_D
I0418 18:17:00.883724 24121 net.cpp:90] Creating Layer conv5_3_D
I0418 18:17:00.883736 24121 net.cpp:410] conv5_3_D <- pool5_D
I0418 18:17:00.883755 24121 net.cpp:368] conv5_3_D -> conv5_3_D
I0418 18:17:00.883775 24121 net.cpp:120] Setting up conv5_3_D
I0418 18:17:00.905738 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.905787 24121 layer_factory.hpp:74] Creating layer conv5_3_D_bn
I0418 18:17:00.905813 24121 net.cpp:90] Creating Layer conv5_3_D_bn
I0418 18:17:00.905832 24121 net.cpp:410] conv5_3_D_bn <- conv5_3_D
I0418 18:17:00.905851 24121 net.cpp:357] conv5_3_D_bn -> conv5_3_D (in-place)
I0418 18:17:00.905872 24121 net.cpp:120] Setting up conv5_3_D_bn
I0418 18:17:00.905915 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.905932 24121 layer_factory.hpp:74] Creating layer relu5_3_D
I0418 18:17:00.905946 24121 net.cpp:90] Creating Layer relu5_3_D
I0418 18:17:00.905962 24121 net.cpp:410] relu5_3_D <- conv5_3_D
I0418 18:17:00.905974 24121 net.cpp:357] relu5_3_D -> conv5_3_D (in-place)
I0418 18:17:00.905993 24121 net.cpp:120] Setting up relu5_3_D
I0418 18:17:00.908184 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.908200 24121 layer_factory.hpp:74] Creating layer conv5_2_D
I0418 18:17:00.908215 24121 net.cpp:90] Creating Layer conv5_2_D
I0418 18:17:00.908228 24121 net.cpp:410] conv5_2_D <- conv5_3_D
I0418 18:17:00.908246 24121 net.cpp:368] conv5_2_D -> conv5_2_D
I0418 18:17:00.908267 24121 net.cpp:120] Setting up conv5_2_D
I0418 18:17:00.956156 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.956200 24121 layer_factory.hpp:74] Creating layer conv5_2_D_bn
I0418 18:17:00.956223 24121 net.cpp:90] Creating Layer conv5_2_D_bn
I0418 18:17:00.956239 24121 net.cpp:410] conv5_2_D_bn <- conv5_2_D
I0418 18:17:00.956259 24121 net.cpp:357] conv5_2_D_bn -> conv5_2_D (in-place)
I0418 18:17:00.956277 24121 net.cpp:120] Setting up conv5_2_D_bn
I0418 18:17:00.956318 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.956336 24121 layer_factory.hpp:74] Creating layer relu5_2_D
I0418 18:17:00.956351 24121 net.cpp:90] Creating Layer relu5_2_D
I0418 18:17:00.956367 24121 net.cpp:410] relu5_2_D <- conv5_2_D
I0418 18:17:00.956379 24121 net.cpp:357] relu5_2_D -> conv5_2_D (in-place)
I0418 18:17:00.956392 24121 net.cpp:120] Setting up relu5_2_D
I0418 18:17:00.957264 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:00.957278 24121 layer_factory.hpp:74] Creating layer conv5_1_D
I0418 18:17:00.957293 24121 net.cpp:90] Creating Layer conv5_1_D
I0418 18:17:00.957306 24121 net.cpp:410] conv5_1_D <- conv5_2_D
I0418 18:17:00.957327 24121 net.cpp:368] conv5_1_D -> conv5_1_D
I0418 18:17:00.957348 24121 net.cpp:120] Setting up conv5_1_D
I0418 18:17:01.002688 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:01.002732 24121 layer_factory.hpp:74] Creating layer conv5_1_D_bn
I0418 18:17:01.002754 24121 net.cpp:90] Creating Layer conv5_1_D_bn
I0418 18:17:01.002771 24121 net.cpp:410] conv5_1_D_bn <- conv5_1_D
I0418 18:17:01.002785 24121 net.cpp:357] conv5_1_D_bn -> conv5_1_D (in-place)
I0418 18:17:01.002804 24121 net.cpp:120] Setting up conv5_1_D_bn
I0418 18:17:01.002849 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:01.002867 24121 layer_factory.hpp:74] Creating layer relu5_1_D
I0418 18:17:01.002882 24121 net.cpp:90] Creating Layer relu5_1_D
I0418 18:17:01.002892 24121 net.cpp:410] relu5_1_D <- conv5_1_D
I0418 18:17:01.002907 24121 net.cpp:357] relu5_1_D -> conv5_1_D (in-place)
I0418 18:17:01.002923 24121 net.cpp:120] Setting up relu5_1_D
I0418 18:17:01.025312 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:01.025326 24121 layer_factory.hpp:74] Creating layer upsample4_drop
I0418 18:17:01.025341 24121 net.cpp:90] Creating Layer upsample4_drop
I0418 18:17:01.025353 24121 net.cpp:410] upsample4_drop <- conv5_1_D
I0418 18:17:01.025399 24121 net.cpp:357] upsample4_drop -> conv5_1_D (in-place)
I0418 18:17:01.025418 24121 net.cpp:120] Setting up upsample4_drop
I0418 18:17:01.025439 24121 net.cpp:127] Top shape: 2 512 32 32 (1048576)
I0418 18:17:01.025451 24121 layer_factory.hpp:74] Creating layer upsample4
I0418 18:17:01.025480 24121 net.cpp:90] Creating Layer upsample4
I0418 18:17:01.025496 24121 net.cpp:410] upsample4 <- conv5_1_D
I0418 18:17:01.025508 24121 net.cpp:410] upsample4 <- pool4_mask
I0418 18:17:01.025521 24121 net.cpp:368] upsample4 -> pool4_D
I0418 18:17:01.025537 24121 net.cpp:120] Setting up upsample4
I0418 18:17:01.025557 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:01.025571 24121 layer_factory.hpp:74] Creating layer conv4_3_D
I0418 18:17:01.025590 24121 net.cpp:90] Creating Layer conv4_3_D
I0418 18:17:01.025604 24121 net.cpp:410] conv4_3_D <- pool4_D
I0418 18:17:01.025622 24121 net.cpp:368] conv4_3_D -> conv4_3_D
I0418 18:17:01.025646 24121 net.cpp:120] Setting up conv4_3_D
I0418 18:17:01.070773 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:01.070842 24121 layer_factory.hpp:74] Creating layer conv4_3_D_bn
I0418 18:17:01.070866 24121 net.cpp:90] Creating Layer conv4_3_D_bn
I0418 18:17:01.070879 24121 net.cpp:410] conv4_3_D_bn <- conv4_3_D
I0418 18:17:01.070897 24121 net.cpp:357] conv4_3_D_bn -> conv4_3_D (in-place)
I0418 18:17:01.070919 24121 net.cpp:120] Setting up conv4_3_D_bn
I0418 18:17:01.070965 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:01.070981 24121 layer_factory.hpp:74] Creating layer relu4_3_D
I0418 18:17:01.070996 24121 net.cpp:90] Creating Layer relu4_3_D
I0418 18:17:01.071007 24121 net.cpp:410] relu4_3_D <- conv4_3_D
I0418 18:17:01.071022 24121 net.cpp:357] relu4_3_D -> conv4_3_D (in-place)
I0418 18:17:01.071036 24121 net.cpp:120] Setting up relu4_3_D
I0418 18:17:01.074178 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:01.074193 24121 layer_factory.hpp:74] Creating layer conv4_2_D
I0418 18:17:01.074211 24121 net.cpp:90] Creating Layer conv4_2_D
I0418 18:17:01.074225 24121 net.cpp:410] conv4_2_D <- conv4_3_D
I0418 18:17:01.074240 24121 net.cpp:368] conv4_2_D -> conv4_2_D
I0418 18:17:01.074264 24121 net.cpp:120] Setting up conv4_2_D
I0418 18:17:01.097118 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:01.097163 24121 layer_factory.hpp:74] Creating layer conv4_2_D_bn
I0418 18:17:01.097190 24121 net.cpp:90] Creating Layer conv4_2_D_bn
I0418 18:17:01.097204 24121 net.cpp:410] conv4_2_D_bn <- conv4_2_D
I0418 18:17:01.097219 24121 net.cpp:357] conv4_2_D_bn -> conv4_2_D (in-place)
I0418 18:17:01.097237 24121 net.cpp:120] Setting up conv4_2_D_bn
I0418 18:17:01.097285 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:01.097302 24121 layer_factory.hpp:74] Creating layer relu4_2_D
I0418 18:17:01.097319 24121 net.cpp:90] Creating Layer relu4_2_D
I0418 18:17:01.097333 24121 net.cpp:410] relu4_2_D <- conv4_2_D
I0418 18:17:01.097347 24121 net.cpp:357] relu4_2_D -> conv4_2_D (in-place)
I0418 18:17:01.097365 24121 net.cpp:120] Setting up relu4_2_D
I0418 18:17:01.132680 24121 net.cpp:127] Top shape: 2 512 63 63 (4064256)
I0418 18:17:01.132694 24121 layer_factory.hpp:74] Creating layer conv4_1_D
I0418 18:17:01.132709 24121 net.cpp:90] Creating Layer conv4_1_D
I0418 18:17:01.132722 24121 net.cpp:410] conv4_1_D <- conv4_2_D
I0418 18:17:01.132741 24121 net.cpp:368] conv4_1_D -> conv4_1_D
I0418 18:17:01.132757 24121 net.cpp:120] Setting up conv4_1_D
I0418 18:17:01.155412 24121 net.cpp:127] Top shape: 2 256 63 63 (2032128)
I0418 18:17:01.155443 24121 layer_factory.hpp:74] Creating layer conv4_1_D_bn
I0418 18:17:01.155463 24121 net.cpp:90] Creating Layer conv4_1_D_bn
I0418 18:17:01.155478 24121 net.cpp:410] conv4_1_D_bn <- conv4_1_D
I0418 18:17:01.155495 24121 net.cpp:357] conv4_1_D_bn -> conv4_1_D (in-place)
I0418 18:17:01.155511 24121 net.cpp:120] Setting up conv4_1_D_bn
I0418 18:17:01.155565 24121 net.cpp:127] Top shape: 2 256 63 63 (2032128)
I0418 18:17:01.155581 24121 layer_factory.hpp:74] Creating layer relu4_1_D
I0418 18:17:01.155617 24121 net.cpp:90] Creating Layer relu4_1_D
I0418 18:17:01.155628 24121 net.cpp:410] relu4_1_D <- conv4_1_D
I0418 18:17:01.155644 24121 net.cpp:357] relu4_1_D -> conv4_1_D (in-place)
I0418 18:17:01.155660 24121 net.cpp:120] Setting up relu4_1_D
I0418 18:17:01.158809 24121 net.cpp:127] Top shape: 2 256 63 63 (2032128)
I0418 18:17:01.158823 24121 layer_factory.hpp:74] Creating layer upsample3_drop
I0418 18:17:01.158836 24121 net.cpp:90] Creating Layer upsample3_drop
I0418 18:17:01.158845 24121 net.cpp:410] upsample3_drop <- conv4_1_D
I0418 18:17:01.158865 24121 net.cpp:357] upsample3_drop -> conv4_1_D (in-place)
I0418 18:17:01.158886 24121 net.cpp:120] Setting up upsample3_drop
I0418 18:17:01.158905 24121 net.cpp:127] Top shape: 2 256 63 63 (2032128)
I0418 18:17:01.158917 24121 layer_factory.hpp:74] Creating layer upsample3
I0418 18:17:01.158931 24121 net.cpp:90] Creating Layer upsample3
I0418 18:17:01.158946 24121 net.cpp:410] upsample3 <- conv4_1_D
I0418 18:17:01.158957 24121 net.cpp:410] upsample3 <- pool3_mask
I0418 18:17:01.158974 24121 net.cpp:368] upsample3 -> pool3_D
I0418 18:17:01.158993 24121 net.cpp:120] Setting up upsample3
I0418 18:17:01.159009 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:01.159023 24121 layer_factory.hpp:74] Creating layer conv3_3_D
I0418 18:17:01.159037 24121 net.cpp:90] Creating Layer conv3_3_D
I0418 18:17:01.159047 24121 net.cpp:410] conv3_3_D <- pool3_D
I0418 18:17:01.159063 24121 net.cpp:368] conv3_3_D -> conv3_3_D
I0418 18:17:01.159078 24121 net.cpp:120] Setting up conv3_3_D
I0418 18:17:01.173573 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:01.173620 24121 layer_factory.hpp:74] Creating layer conv3_3_D_bn
I0418 18:17:01.173653 24121 net.cpp:90] Creating Layer conv3_3_D_bn
I0418 18:17:01.173673 24121 net.cpp:410] conv3_3_D_bn <- conv3_3_D
I0418 18:17:01.173697 24121 net.cpp:357] conv3_3_D_bn -> conv3_3_D (in-place)
I0418 18:17:01.173717 24121 net.cpp:120] Setting up conv3_3_D_bn
I0418 18:17:01.173807 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:01.173830 24121 layer_factory.hpp:74] Creating layer relu3_3_D
I0418 18:17:01.173851 24121 net.cpp:90] Creating Layer relu3_3_D
I0418 18:17:01.173863 24121 net.cpp:410] relu3_3_D <- conv3_3_D
I0418 18:17:01.173879 24121 net.cpp:357] relu3_3_D -> conv3_3_D (in-place)
I0418 18:17:01.173892 24121 net.cpp:120] Setting up relu3_3_D
I0418 18:17:01.182548 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:01.182564 24121 layer_factory.hpp:74] Creating layer conv3_2_D
I0418 18:17:01.182579 24121 net.cpp:90] Creating Layer conv3_2_D
I0418 18:17:01.182592 24121 net.cpp:410] conv3_2_D <- conv3_3_D
I0418 18:17:01.182612 24121 net.cpp:368] conv3_2_D -> conv3_2_D
I0418 18:17:01.182636 24121 net.cpp:120] Setting up conv3_2_D
I0418 18:17:01.197958 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:01.197978 24121 layer_factory.hpp:74] Creating layer conv3_2_D_bn
I0418 18:17:01.198001 24121 net.cpp:90] Creating Layer conv3_2_D_bn
I0418 18:17:01.198012 24121 net.cpp:410] conv3_2_D_bn <- conv3_2_D
I0418 18:17:01.198024 24121 net.cpp:357] conv3_2_D_bn -> conv3_2_D (in-place)
I0418 18:17:01.198045 24121 net.cpp:120] Setting up conv3_2_D_bn
I0418 18:17:01.198134 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:01.198156 24121 layer_factory.hpp:74] Creating layer relu3_2_D
I0418 18:17:01.198174 24121 net.cpp:90] Creating Layer relu3_2_D
I0418 18:17:01.198184 24121 net.cpp:410] relu3_2_D <- conv3_2_D
I0418 18:17:01.198199 24121 net.cpp:357] relu3_2_D -> conv3_2_D (in-place)
I0418 18:17:01.198217 24121 net.cpp:120] Setting up relu3_2_D
I0418 18:17:01.202513 24121 net.cpp:127] Top shape: 2 256 125 125 (8000000)
I0418 18:17:01.202529 24121 layer_factory.hpp:74] Creating layer conv3_1_D
I0418 18:17:01.202548 24121 net.cpp:90] Creating Layer conv3_1_D
I0418 18:17:01.202561 24121 net.cpp:410] conv3_1_D <- conv3_2_D
I0418 18:17:01.202577 24121 net.cpp:368] conv3_1_D -> conv3_1_D
I0418 18:17:01.202596 24121 net.cpp:120] Setting up conv3_1_D
I0418 18:17:01.213762 24121 net.cpp:127] Top shape: 2 128 125 125 (4000000)
I0418 18:17:01.213783 24121 layer_factory.hpp:74] Creating layer conv3_1_D_bn
I0418 18:17:01.213809 24121 net.cpp:90] Creating Layer conv3_1_D_bn
I0418 18:17:01.213824 24121 net.cpp:410] conv3_1_D_bn <- conv3_1_D
I0418 18:17:01.213838 24121 net.cpp:357] conv3_1_D_bn -> conv3_1_D (in-place)
I0418 18:17:01.213857 24121 net.cpp:120] Setting up conv3_1_D_bn
I0418 18:17:01.213948 24121 net.cpp:127] Top shape: 2 128 125 125 (4000000)
I0418 18:17:01.213970 24121 layer_factory.hpp:74] Creating layer relu3_1_D
I0418 18:17:01.213987 24121 net.cpp:90] Creating Layer relu3_1_D
I0418 18:17:01.213996 24121 net.cpp:410] relu3_1_D <- conv3_1_D
I0418 18:17:01.214012 24121 net.cpp:357] relu3_1_D -> conv3_1_D (in-place)
I0418 18:17:01.214030 24121 net.cpp:120] Setting up relu3_1_D
I0418 18:17:01.218425 24121 net.cpp:127] Top shape: 2 128 125 125 (4000000)
I0418 18:17:01.218441 24121 layer_factory.hpp:74] Creating layer upsample2_drop
I0418 18:17:01.218461 24121 net.cpp:90] Creating Layer upsample2_drop
I0418 18:17:01.218475 24121 net.cpp:410] upsample2_drop <- conv3_1_D
I0418 18:17:01.218487 24121 net.cpp:357] upsample2_drop -> conv3_1_D (in-place)
I0418 18:17:01.218500 24121 net.cpp:120] Setting up upsample2_drop
I0418 18:17:01.218519 24121 net.cpp:127] Top shape: 2 128 125 125 (4000000)
I0418 18:17:01.218533 24121 layer_factory.hpp:74] Creating layer upsample2
I0418 18:17:01.218552 24121 net.cpp:90] Creating Layer upsample2
I0418 18:17:01.218564 24121 net.cpp:410] upsample2 <- conv3_1_D
I0418 18:17:01.218580 24121 net.cpp:410] upsample2 <- pool2_mask
I0418 18:17:01.218598 24121 net.cpp:368] upsample2 -> pool2_D
I0418 18:17:01.218617 24121 net.cpp:120] Setting up upsample2
I0418 18:17:01.218631 24121 upsample_layer.cpp:31] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0418 18:17:01.218647 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:17:01.218657 24121 layer_factory.hpp:74] Creating layer conv2_2_D
I0418 18:17:01.218673 24121 net.cpp:90] Creating Layer conv2_2_D
I0418 18:17:01.218688 24121 net.cpp:410] conv2_2_D <- pool2_D
I0418 18:17:01.218706 24121 net.cpp:368] conv2_2_D -> conv2_2_D
I0418 18:17:01.218724 24121 net.cpp:120] Setting up conv2_2_D
I0418 18:17:01.230780 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:17:01.230801 24121 layer_factory.hpp:74] Creating layer conv2_2_D_bn
I0418 18:17:01.230826 24121 net.cpp:90] Creating Layer conv2_2_D_bn
I0418 18:17:01.230837 24121 net.cpp:410] conv2_2_D_bn <- conv2_2_D
I0418 18:17:01.230850 24121 net.cpp:357] conv2_2_D_bn -> conv2_2_D (in-place)
I0418 18:17:01.230871 24121 net.cpp:120] Setting up conv2_2_D_bn
I0418 18:17:01.231130 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:17:01.231154 24121 layer_factory.hpp:74] Creating layer relu2_2_D
I0418 18:17:01.231169 24121 net.cpp:90] Creating Layer relu2_2_D
I0418 18:17:01.231178 24121 net.cpp:410] relu2_2_D <- conv2_2_D
I0418 18:17:01.231194 24121 net.cpp:357] relu2_2_D -> conv2_2_D (in-place)
I0418 18:17:01.231212 24121 net.cpp:120] Setting up relu2_2_D
I0418 18:17:01.234123 24121 net.cpp:127] Top shape: 2 128 250 250 (16000000)
I0418 18:17:01.234138 24121 layer_factory.hpp:74] Creating layer conv2_1_D
I0418 18:17:01.234158 24121 net.cpp:90] Creating Layer conv2_1_D
I0418 18:17:01.234172 24121 net.cpp:410] conv2_1_D <- conv2_2_D
I0418 18:17:01.234190 24121 net.cpp:368] conv2_1_D -> conv2_1_D
I0418 18:17:01.234210 24121 net.cpp:120] Setting up conv2_1_D
I0418 18:17:01.244992 24121 net.cpp:127] Top shape: 2 64 250 250 (8000000)
I0418 18:17:01.245012 24121 layer_factory.hpp:74] Creating layer conv2_1_D_bn
I0418 18:17:01.245028 24121 net.cpp:90] Creating Layer conv2_1_D_bn
I0418 18:17:01.245041 24121 net.cpp:410] conv2_1_D_bn <- conv2_1_D
I0418 18:17:01.245057 24121 net.cpp:357] conv2_1_D_bn -> conv2_1_D (in-place)
I0418 18:17:01.245079 24121 net.cpp:120] Setting up conv2_1_D_bn
I0418 18:17:01.245332 24121 net.cpp:127] Top shape: 2 64 250 250 (8000000)
I0418 18:17:01.245362 24121 layer_factory.hpp:74] Creating layer relu2_1_D
I0418 18:17:01.245379 24121 net.cpp:90] Creating Layer relu2_1_D
I0418 18:17:01.245389 24121 net.cpp:410] relu2_1_D <- conv2_1_D
I0418 18:17:01.245404 24121 net.cpp:357] relu2_1_D -> conv2_1_D (in-place)
I0418 18:17:01.245424 24121 net.cpp:120] Setting up relu2_1_D
I0418 18:17:01.248512 24121 net.cpp:127] Top shape: 2 64 250 250 (8000000)
I0418 18:17:01.248525 24121 layer_factory.hpp:74] Creating layer upsample1_drop
I0418 18:17:01.248540 24121 net.cpp:90] Creating Layer upsample1_drop
I0418 18:17:01.248553 24121 net.cpp:410] upsample1_drop <- conv2_1_D
I0418 18:17:01.248566 24121 net.cpp:357] upsample1_drop -> conv2_1_D (in-place)
I0418 18:17:01.248579 24121 net.cpp:120] Setting up upsample1_drop
I0418 18:17:01.248594 24121 net.cpp:127] Top shape: 2 64 250 250 (8000000)
I0418 18:17:01.248603 24121 layer_factory.hpp:74] Creating layer upsample1
I0418 18:17:01.248617 24121 net.cpp:90] Creating Layer upsample1
I0418 18:17:01.248631 24121 net.cpp:410] upsample1 <- conv2_1_D
I0418 18:17:01.248644 24121 net.cpp:410] upsample1 <- pool1_mask
I0418 18:17:01.248661 24121 net.cpp:368] upsample1 -> pool1_D
I0418 18:17:01.248677 24121 net.cpp:120] Setting up upsample1
I0418 18:17:01.248687 24121 upsample_layer.cpp:31] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0418 18:17:01.248702 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:17:01.248714 24121 layer_factory.hpp:74] Creating layer conv1_2_D
I0418 18:17:01.248735 24121 net.cpp:90] Creating Layer conv1_2_D
I0418 18:17:01.248747 24121 net.cpp:410] conv1_2_D <- pool1_D
I0418 18:17:01.248761 24121 net.cpp:368] conv1_2_D -> conv1_2_D
I0418 18:17:01.248775 24121 net.cpp:120] Setting up conv1_2_D
I0418 18:17:01.264698 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:17:01.264719 24121 layer_factory.hpp:74] Creating layer conv1_2_D_bn
I0418 18:17:01.264740 24121 net.cpp:90] Creating Layer conv1_2_D_bn
I0418 18:17:01.264751 24121 net.cpp:410] conv1_2_D_bn <- conv1_2_D
I0418 18:17:01.264766 24121 net.cpp:357] conv1_2_D_bn -> conv1_2_D (in-place)
I0418 18:17:01.264786 24121 net.cpp:120] Setting up conv1_2_D_bn
I0418 18:17:01.265662 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:17:01.265682 24121 layer_factory.hpp:74] Creating layer relu1_2_D
I0418 18:17:01.265698 24121 net.cpp:90] Creating Layer relu1_2_D
I0418 18:17:01.265712 24121 net.cpp:410] relu1_2_D <- conv1_2_D
I0418 18:17:01.265723 24121 net.cpp:357] relu1_2_D -> conv1_2_D (in-place)
I0418 18:17:01.265736 24121 net.cpp:120] Setting up relu1_2_D
I0418 18:17:01.267890 24121 net.cpp:127] Top shape: 2 64 500 500 (32000000)
I0418 18:17:01.267904 24121 layer_factory.hpp:74] Creating layer conv1_1_D
I0418 18:17:01.267920 24121 net.cpp:90] Creating Layer conv1_1_D
I0418 18:17:01.267932 24121 net.cpp:410] conv1_1_D <- conv1_2_D
I0418 18:17:01.267951 24121 net.cpp:368] conv1_1_D -> conv1_1_D
I0418 18:17:01.267969 24121 net.cpp:120] Setting up conv1_1_D
I0418 18:17:01.280441 24121 net.cpp:127] Top shape: 2 21 500 500 (10500000)
I0418 18:17:01.280462 24121 layer_factory.hpp:74] Creating layer conv1_1_D_conv1_1_D_0_split
I0418 18:17:01.280475 24121 net.cpp:90] Creating Layer conv1_1_D_conv1_1_D_0_split
I0418 18:17:01.280488 24121 net.cpp:410] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0418 18:17:01.280501 24121 net.cpp:368] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0418 18:17:01.280519 24121 net.cpp:368] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0418 18:17:01.280539 24121 net.cpp:120] Setting up conv1_1_D_conv1_1_D_0_split
I0418 18:17:01.280557 24121 net.cpp:127] Top shape: 2 21 500 500 (10500000)
I0418 18:17:01.280575 24121 net.cpp:127] Top shape: 2 21 500 500 (10500000)
I0418 18:17:01.280585 24121 layer_factory.hpp:74] Creating layer loss
I0418 18:17:01.280599 24121 net.cpp:90] Creating Layer loss
I0418 18:17:01.280611 24121 net.cpp:410] loss <- conv1_1_D_conv1_1_D_0_split_0
I0418 18:17:01.280623 24121 net.cpp:410] loss <- label_label_0_split_0
I0418 18:17:01.280657 24121 net.cpp:368] loss -> loss
I0418 18:17:01.280673 24121 net.cpp:120] Setting up loss
I0418 18:17:01.280689 24121 layer_factory.hpp:74] Creating layer loss
I0418 18:17:01.296407 24121 net.cpp:127] Top shape: (1)
I0418 18:17:01.296447 24121 net.cpp:129]     with loss weight 1
I0418 18:17:01.296474 24121 layer_factory.hpp:74] Creating layer accuracy
I0418 18:17:01.296496 24121 net.cpp:90] Creating Layer accuracy
I0418 18:17:01.296509 24121 net.cpp:410] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0418 18:17:01.296520 24121 net.cpp:410] accuracy <- label_label_0_split_1
I0418 18:17:01.296537 24121 net.cpp:368] accuracy -> accuracy
I0418 18:17:01.296553 24121 net.cpp:368] accuracy -> per_class_accuracy
I0418 18:17:01.296567 24121 net.cpp:120] Setting up accuracy
I0418 18:17:01.296591 24121 accuracy_layer.cpp:24] Per-class accuracies currently only work on TRAIN phase only.
I0418 18:17:01.296605 24121 net.cpp:127] Top shape: (1)
I0418 18:17:01.296620 24121 net.cpp:127] Top shape: 21 1 1 1 (21)
I0418 18:17:01.296632 24121 net.cpp:194] accuracy does not need backward computation.
I0418 18:17:01.296643 24121 net.cpp:192] loss needs backward computation.
I0418 18:17:01.296653 24121 net.cpp:192] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0418 18:17:01.296661 24121 net.cpp:192] conv1_1_D needs backward computation.
I0418 18:17:01.296671 24121 net.cpp:192] relu1_2_D needs backward computation.
I0418 18:17:01.296680 24121 net.cpp:192] conv1_2_D_bn needs backward computation.
I0418 18:17:01.296689 24121 net.cpp:192] conv1_2_D needs backward computation.
I0418 18:17:01.296697 24121 net.cpp:192] upsample1 needs backward computation.
I0418 18:17:01.296707 24121 net.cpp:192] upsample1_drop needs backward computation.
I0418 18:17:01.296716 24121 net.cpp:192] relu2_1_D needs backward computation.
I0418 18:17:01.296725 24121 net.cpp:192] conv2_1_D_bn needs backward computation.
I0418 18:17:01.296733 24121 net.cpp:192] conv2_1_D needs backward computation.
I0418 18:17:01.296742 24121 net.cpp:192] relu2_2_D needs backward computation.
I0418 18:17:01.296752 24121 net.cpp:192] conv2_2_D_bn needs backward computation.
I0418 18:17:01.296761 24121 net.cpp:192] conv2_2_D needs backward computation.
I0418 18:17:01.296771 24121 net.cpp:192] upsample2 needs backward computation.
I0418 18:17:01.296779 24121 net.cpp:192] upsample2_drop needs backward computation.
I0418 18:17:01.296788 24121 net.cpp:192] relu3_1_D needs backward computation.
I0418 18:17:01.296797 24121 net.cpp:192] conv3_1_D_bn needs backward computation.
I0418 18:17:01.296805 24121 net.cpp:192] conv3_1_D needs backward computation.
I0418 18:17:01.296814 24121 net.cpp:192] relu3_2_D needs backward computation.
I0418 18:17:01.296823 24121 net.cpp:192] conv3_2_D_bn needs backward computation.
I0418 18:17:01.296831 24121 net.cpp:192] conv3_2_D needs backward computation.
I0418 18:17:01.296840 24121 net.cpp:192] relu3_3_D needs backward computation.
I0418 18:17:01.296849 24121 net.cpp:192] conv3_3_D_bn needs backward computation.
I0418 18:17:01.296857 24121 net.cpp:192] conv3_3_D needs backward computation.
I0418 18:17:01.296866 24121 net.cpp:192] upsample3 needs backward computation.
I0418 18:17:01.296878 24121 net.cpp:192] upsample3_drop needs backward computation.
I0418 18:17:01.296890 24121 net.cpp:192] relu4_1_D needs backward computation.
I0418 18:17:01.296900 24121 net.cpp:192] conv4_1_D_bn needs backward computation.
I0418 18:17:01.296910 24121 net.cpp:192] conv4_1_D needs backward computation.
I0418 18:17:01.296921 24121 net.cpp:192] relu4_2_D needs backward computation.
I0418 18:17:01.296931 24121 net.cpp:192] conv4_2_D_bn needs backward computation.
I0418 18:17:01.296941 24121 net.cpp:192] conv4_2_D needs backward computation.
I0418 18:17:01.296952 24121 net.cpp:192] relu4_3_D needs backward computation.
I0418 18:17:01.296962 24121 net.cpp:192] conv4_3_D_bn needs backward computation.
I0418 18:17:01.296973 24121 net.cpp:192] conv4_3_D needs backward computation.
I0418 18:17:01.296983 24121 net.cpp:192] upsample4 needs backward computation.
I0418 18:17:01.297019 24121 net.cpp:192] upsample4_drop needs backward computation.
I0418 18:17:01.297030 24121 net.cpp:192] relu5_1_D needs backward computation.
I0418 18:17:01.297041 24121 net.cpp:192] conv5_1_D_bn needs backward computation.
I0418 18:17:01.297050 24121 net.cpp:192] conv5_1_D needs backward computation.
I0418 18:17:01.297060 24121 net.cpp:192] relu5_2_D needs backward computation.
I0418 18:17:01.297068 24121 net.cpp:192] conv5_2_D_bn needs backward computation.
I0418 18:17:01.297077 24121 net.cpp:192] conv5_2_D needs backward computation.
I0418 18:17:01.297086 24121 net.cpp:192] relu5_3_D needs backward computation.
I0418 18:17:01.297096 24121 net.cpp:192] conv5_3_D_bn needs backward computation.
I0418 18:17:01.297104 24121 net.cpp:192] conv5_3_D needs backward computation.
I0418 18:17:01.297116 24121 net.cpp:192] upsample5 needs backward computation.
I0418 18:17:01.297125 24121 net.cpp:192] upsample5_drop needs backward computation.
I0418 18:17:01.297133 24121 net.cpp:192] pool5 needs backward computation.
I0418 18:17:01.297143 24121 net.cpp:192] pool5_drop needs backward computation.
I0418 18:17:01.297152 24121 net.cpp:192] relu5_3 needs backward computation.
I0418 18:17:01.297161 24121 net.cpp:192] conv5_3_bn needs backward computation.
I0418 18:17:01.297170 24121 net.cpp:192] conv5_3 needs backward computation.
I0418 18:17:01.297179 24121 net.cpp:192] relu5_2 needs backward computation.
I0418 18:17:01.297188 24121 net.cpp:192] conv5_2_bn needs backward computation.
I0418 18:17:01.297196 24121 net.cpp:192] conv5_2 needs backward computation.
I0418 18:17:01.297206 24121 net.cpp:192] relu5_1 needs backward computation.
I0418 18:17:01.297214 24121 net.cpp:192] conv5_1_bn needs backward computation.
I0418 18:17:01.297224 24121 net.cpp:192] conv5_1 needs backward computation.
I0418 18:17:01.297232 24121 net.cpp:192] pool4 needs backward computation.
I0418 18:17:01.297241 24121 net.cpp:192] pool4_drop needs backward computation.
I0418 18:17:01.297250 24121 net.cpp:192] relu4_3 needs backward computation.
I0418 18:17:01.297260 24121 net.cpp:192] conv4_3_bn needs backward computation.
I0418 18:17:01.297267 24121 net.cpp:192] conv4_3 needs backward computation.
I0418 18:17:01.297277 24121 net.cpp:192] relu4_2 needs backward computation.
I0418 18:17:01.297286 24121 net.cpp:192] conv4_2_bn needs backward computation.
I0418 18:17:01.297294 24121 net.cpp:192] conv4_2 needs backward computation.
I0418 18:17:01.297303 24121 net.cpp:192] relu4_1 needs backward computation.
I0418 18:17:01.297312 24121 net.cpp:192] conv4_1_bn needs backward computation.
I0418 18:17:01.297322 24121 net.cpp:192] conv4_1 needs backward computation.
I0418 18:17:01.297332 24121 net.cpp:192] pool3 needs backward computation.
I0418 18:17:01.297340 24121 net.cpp:192] pool3_drop needs backward computation.
I0418 18:17:01.297350 24121 net.cpp:192] relu3_3 needs backward computation.
I0418 18:17:01.297359 24121 net.cpp:192] conv3_3_bn needs backward computation.
I0418 18:17:01.297370 24121 net.cpp:192] conv3_3 needs backward computation.
I0418 18:17:01.297379 24121 net.cpp:192] relu3_2 needs backward computation.
I0418 18:17:01.297387 24121 net.cpp:192] conv3_2_bn needs backward computation.
I0418 18:17:01.297396 24121 net.cpp:192] conv3_2 needs backward computation.
I0418 18:17:01.297407 24121 net.cpp:192] relu3_1 needs backward computation.
I0418 18:17:01.297416 24121 net.cpp:192] conv3_1_bn needs backward computation.
I0418 18:17:01.297425 24121 net.cpp:192] conv3_1 needs backward computation.
I0418 18:17:01.297435 24121 net.cpp:192] pool2 needs backward computation.
I0418 18:17:01.297443 24121 net.cpp:192] pool2_drop needs backward computation.
I0418 18:17:01.297452 24121 net.cpp:192] relu2_2 needs backward computation.
I0418 18:17:01.297463 24121 net.cpp:192] conv2_2_bn needs backward computation.
I0418 18:17:01.297473 24121 net.cpp:192] conv2_2 needs backward computation.
I0418 18:17:01.297483 24121 net.cpp:192] relu2_1 needs backward computation.
I0418 18:17:01.297494 24121 net.cpp:192] conv2_1_bn needs backward computation.
I0418 18:17:01.297514 24121 net.cpp:192] conv2_1 needs backward computation.
I0418 18:17:01.297528 24121 net.cpp:192] pool1 needs backward computation.
I0418 18:17:01.297544 24121 net.cpp:192] pool1_drop needs backward computation.
I0418 18:17:01.297554 24121 net.cpp:192] relu1_2 needs backward computation.
I0418 18:17:01.297566 24121 net.cpp:192] conv1_2_bn needs backward computation.
I0418 18:17:01.297576 24121 net.cpp:192] conv1_2 needs backward computation.
I0418 18:17:01.297588 24121 net.cpp:192] relu1_1 needs backward computation.
I0418 18:17:01.297605 24121 net.cpp:192] conv1_1_bn needs backward computation.
I0418 18:17:01.297616 24121 net.cpp:192] conv1_1 needs backward computation.
I0418 18:17:01.297628 24121 net.cpp:194] label_label_0_split does not need backward computation.
I0418 18:17:01.297638 24121 net.cpp:194] label does not need backward computation.
I0418 18:17:01.297647 24121 net.cpp:194] data does not need backward computation.
I0418 18:17:01.297655 24121 net.cpp:235] This network produces output accuracy
I0418 18:17:01.297664 24121 net.cpp:235] This network produces output loss
I0418 18:17:01.297673 24121 net.cpp:235] This network produces output per_class_accuracy
I0418 18:17:01.297737 24121 net.cpp:482] Collecting Learning Rate and Weight Decay.
I0418 18:17:01.297772 24121 net.cpp:247] Network initialization done.
I0418 18:17:01.297785 24121 net.cpp:248] Memory required for data: 3506755292
I0418 18:17:01.298230 24121 solver.cpp:42] Solver scaffolding done.
I0418 18:17:01.298420 24121 solver.cpp:250] Solving VGG_ILSVRC_16_layer
I0418 18:17:01.298432 24121 solver.cpp:251] Learning Rate Policy: step
I0418 18:17:04.062935 24121 solver.cpp:214] Iteration 0, loss = 1.32283
I0418 18:17:04.062983 24121 solver.cpp:229]     Train net output #0: accuracy = 0.104124
I0418 18:17:04.063005 24121 solver.cpp:229]     Train net output #1: loss = 1.32283 (* 1 = 1.32283 loss)
I0418 18:17:04.063020 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.119193
I0418 18:17:04.063031 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = 0.0226304
I0418 18:17:04.063041 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:17:04.063052 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:17:04.063062 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:17:04.063073 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:17:04.063083 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 18:17:04.063093 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:17:04.063104 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:17:04.063120 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:17:04.063133 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:17:04.063143 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:17:04.063153 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 18:17:04.063164 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:17:04.063175 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:17:04.063186 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.0143229
I0418 18:17:04.063199 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:17:04.063210 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:17:04.063220 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:17:04.063231 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:17:04.063242 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:17:04.063271 24121 solver.cpp:486] Iteration 0, lr = 0.001
I0418 18:18:59.024077 24121 solver.cpp:214] Iteration 20, loss = 1.35767
I0418 18:18:59.024301 24121 solver.cpp:229]     Train net output #0: accuracy = 0.423944
I0418 18:18:59.024318 24121 solver.cpp:229]     Train net output #1: loss = 1.35767 (* 1 = 1.35767 loss)
I0418 18:18:59.024327 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.770292
I0418 18:18:59.024334 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:18:59.024339 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:18:59.024344 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:18:59.024351 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:18:59.024356 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:18:59.024363 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = 0.00153721
I0418 18:18:59.024369 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = 0.0061282
I0418 18:18:59.024374 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:18:59.024379 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = 0.01
I0418 18:18:59.024389 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:18:59.024394 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:18:59.024400 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 18:18:59.024405 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:18:59.024410 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:18:59.024416 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = -nan
I0418 18:18:59.024421 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = 0.00458248
I0418 18:18:59.024427 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:18:59.024433 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = 0.00834423
I0418 18:18:59.024440 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:18:59.024444 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:18:59.024457 24121 solver.cpp:486] Iteration 20, lr = 0.001
I0418 18:20:53.445925 24121 solver.cpp:214] Iteration 40, loss = 1.17994
I0418 18:20:53.446041 24121 solver.cpp:229]     Train net output #0: accuracy = 0.715032
I0418 18:20:53.446058 24121 solver.cpp:229]     Train net output #1: loss = 1.17994 (* 1 = 1.17994 loss)
I0418 18:20:53.446066 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.983308
I0418 18:20:53.446074 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:20:53.446079 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:20:53.446084 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:20:53.446089 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:20:53.446094 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = 6.76178e-05
I0418 18:20:53.446100 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 18:20:53.446106 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:20:53.446115 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:20:53.446121 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:20:53.446126 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:20:53.446135 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:20:53.446141 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = 0.000125376
I0418 18:20:53.446147 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:20:53.446152 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:20:53.446158 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.0166055
I0418 18:20:53.446164 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = 0
I0418 18:20:53.446171 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:20:53.446176 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:20:53.446180 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:20:53.446187 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:20:53.446198 24121 solver.cpp:486] Iteration 40, lr = 0.001
I0418 18:22:48.389096 24121 solver.cpp:214] Iteration 60, loss = 0.892023
I0418 18:22:48.389446 24121 solver.cpp:229]     Train net output #0: accuracy = 0.611378
I0418 18:22:48.389503 24121 solver.cpp:229]     Train net output #1: loss = 0.892024 (* 1 = 0.892024 loss)
I0418 18:22:48.389530 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.836855
I0418 18:22:48.389544 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:22:48.389554 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:22:48.389564 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:22:48.389575 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:22:48.389585 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:22:48.389595 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = 7.46022e-05
I0418 18:22:48.389606 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:22:48.389617 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:22:48.389623 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:22:48.389629 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:22:48.389634 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:22:48.389639 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 18:22:48.389645 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = 8.54372e-05
I0418 18:22:48.389652 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:22:48.389657 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.181598
I0418 18:22:48.389663 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:22:48.389668 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:22:48.389673 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:22:48.389679 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:22:48.389684 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:22:48.389695 24121 solver.cpp:486] Iteration 60, lr = 0.001
I0418 18:24:40.823680 24121 solver.cpp:214] Iteration 80, loss = 2.12441
I0418 18:24:40.823889 24121 solver.cpp:229]     Train net output #0: accuracy = 0.195084
I0418 18:24:40.823915 24121 solver.cpp:229]     Train net output #1: loss = 2.12441 (* 1 = 2.12441 loss)
I0418 18:24:40.823928 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.928487
I0418 18:24:40.823935 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:24:40.823940 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:24:40.823946 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:24:40.823951 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:24:40.823957 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = 0
I0418 18:24:40.823962 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = 2.20377e-05
I0418 18:24:40.823969 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:24:40.823976 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:24:40.823981 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:24:40.823985 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:24:40.823992 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:24:40.823997 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 18:24:40.824002 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:24:40.824007 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:24:40.824012 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.0762981
I0418 18:24:40.824018 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:24:40.824023 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:24:40.824029 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = 0.000122769
I0418 18:24:40.824035 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:24:40.824040 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:24:40.824054 24121 solver.cpp:486] Iteration 80, lr = 0.001
I0418 18:26:35.297075 24121 solver.cpp:214] Iteration 100, loss = 1.5693
I0418 18:26:35.297387 24121 solver.cpp:229]     Train net output #0: accuracy = 0.46783
I0418 18:26:35.297422 24121 solver.cpp:229]     Train net output #1: loss = 1.5693 (* 1 = 1.5693 loss)
I0418 18:26:35.297432 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.816171
I0418 18:26:35.297440 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:26:35.297446 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:26:35.297451 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:26:35.297456 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:26:35.297461 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:26:35.297466 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = 7.77439e-05
I0418 18:26:35.297473 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = 8.40389e-05
I0418 18:26:35.297479 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:26:35.297485 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:26:35.297490 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:26:35.297497 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:26:35.297502 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 18:26:35.297508 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:26:35.297513 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:26:35.297518 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = -nan
I0418 18:26:35.297523 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:26:35.297528 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:26:35.297533 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:26:35.297539 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:26:35.297544 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:26:35.297556 24121 solver.cpp:486] Iteration 100, lr = 0.001
I0418 18:28:30.202934 24121 solver.cpp:214] Iteration 120, loss = 0.866505
I0418 18:28:30.203045 24121 solver.cpp:229]     Train net output #0: accuracy = 0.569778
I0418 18:28:30.203066 24121 solver.cpp:229]     Train net output #1: loss = 0.866505 (* 1 = 0.866505 loss)
I0418 18:28:30.203075 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.819195
I0418 18:28:30.203081 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:28:30.203088 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:28:30.203094 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:28:30.203099 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:28:30.203104 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:28:30.203120 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = 3.21375e-05
I0418 18:28:30.203128 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:28:30.203133 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:28:30.203140 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:28:30.203145 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:28:30.203150 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:28:30.203155 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 18:28:30.203164 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:28:30.203171 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:28:30.203176 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = -nan
I0418 18:28:30.203181 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:28:30.203186 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = 0
I0418 18:28:30.203193 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:28:30.203198 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:28:30.203203 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:28:30.203215 24121 solver.cpp:486] Iteration 120, lr = 0.001
I0418 18:30:24.454241 24121 solver.cpp:214] Iteration 140, loss = 3.47494
I0418 18:30:24.454641 24121 solver.cpp:229]     Train net output #0: accuracy = 0.467876
I0418 18:30:24.454659 24121 solver.cpp:229]     Train net output #1: loss = 3.47494 (* 1 = 3.47494 loss)
I0418 18:30:24.454668 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.929676
I0418 18:30:24.454674 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = 0.000103769
I0418 18:30:24.454680 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:30:24.454686 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:30:24.454692 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:30:24.454697 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = 0
I0418 18:30:24.454704 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 18:30:24.454710 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:30:24.454715 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:30:24.454720 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:30:24.454725 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:30:24.454730 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:30:24.454735 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 18:30:24.454741 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:30:24.454746 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:30:24.454751 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.0599593
I0418 18:30:24.454757 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:30:24.454763 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:30:24.454768 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:30:24.454773 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:30:24.454779 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:30:24.454790 24121 solver.cpp:486] Iteration 140, lr = 0.001
I0418 18:32:18.688889 24121 solver.cpp:214] Iteration 160, loss = 1.8245
I0418 18:32:18.689278 24121 solver.cpp:229]     Train net output #0: accuracy = 0.396074
I0418 18:32:18.689309 24121 solver.cpp:229]     Train net output #1: loss = 1.8245 (* 1 = 1.8245 loss)
I0418 18:32:18.689323 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.940299
I0418 18:32:18.689335 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:32:18.689345 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:32:18.689355 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:32:18.689365 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:32:18.689375 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:32:18.689384 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 18:32:18.689394 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:32:18.689404 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:32:18.689421 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:32:18.689427 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:32:18.689432 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:32:18.689437 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = 0
I0418 18:32:18.689442 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:32:18.689451 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:32:18.689457 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.0634633
I0418 18:32:18.689463 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:32:18.689468 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:32:18.689473 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:32:18.689479 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:32:18.689484 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:32:18.689496 24121 solver.cpp:486] Iteration 160, lr = 0.001
I0418 18:34:13.331848 24121 solver.cpp:214] Iteration 180, loss = 0.869193
I0418 18:34:13.332048 24121 solver.cpp:229]     Train net output #0: accuracy = 0.729604
I0418 18:34:13.332073 24121 solver.cpp:229]     Train net output #1: loss = 0.869193 (* 1 = 0.869193 loss)
I0418 18:34:13.332084 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.841731
I0418 18:34:13.332092 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = 9.10305e-05
I0418 18:34:13.332098 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:34:13.332104 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:34:13.332109 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:34:13.332114 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:34:13.332120 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 18:34:13.332125 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:34:13.332135 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:34:13.332141 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:34:13.332146 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:34:13.332151 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:34:13.332156 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 18:34:13.332162 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:34:13.332167 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:34:13.332172 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = -nan
I0418 18:34:13.332177 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = 0.000192994
I0418 18:34:13.332185 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:34:13.332190 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:34:13.332195 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:34:13.332201 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:34:13.332211 24121 solver.cpp:486] Iteration 180, lr = 0.001
I0418 18:36:07.676244 24121 solver.cpp:214] Iteration 200, loss = 0.746086
I0418 18:36:07.676543 24121 solver.cpp:229]     Train net output #0: accuracy = 0.756762
I0418 18:36:07.676568 24121 solver.cpp:229]     Train net output #1: loss = 0.746086 (* 1 = 0.746086 loss)
I0418 18:36:07.676579 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.915335
I0418 18:36:07.676586 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:36:07.676591 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:36:07.676597 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:36:07.676602 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:36:07.676609 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:36:07.676614 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 18:36:07.676619 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:36:07.676625 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:36:07.676633 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:36:07.676640 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:36:07.676645 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:36:07.676651 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = 0
I0418 18:36:07.676656 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = 0
I0418 18:36:07.676662 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:36:07.676667 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.0827916
I0418 18:36:07.676678 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:36:07.676689 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:36:07.676700 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:36:07.676712 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:36:07.676723 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:36:07.676740 24121 solver.cpp:486] Iteration 200, lr = 0.001
I0418 18:38:01.937377 24121 solver.cpp:214] Iteration 220, loss = 1.58655
I0418 18:38:01.937567 24121 solver.cpp:229]     Train net output #0: accuracy = 0.46688
I0418 18:38:01.937603 24121 solver.cpp:229]     Train net output #1: loss = 1.58655 (* 1 = 1.58655 loss)
I0418 18:38:01.937613 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.763799
I0418 18:38:01.937620 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:38:01.937626 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:38:01.937631 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = 5.0638e-05
I0418 18:38:01.937638 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:38:01.937644 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = 0
I0418 18:38:01.937650 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 18:38:01.937655 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:38:01.937660 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:38:01.937666 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:38:01.937671 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:38:01.937676 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:38:01.937686 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 18:38:01.937697 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:38:01.937708 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:38:01.937722 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.232218
I0418 18:38:01.937736 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:38:01.937742 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = 3.9562e-05
I0418 18:38:01.937749 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:38:01.937754 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:38:01.937760 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:38:01.937769 24121 solver.cpp:486] Iteration 220, lr = 0.001
I0418 18:39:55.989125 24121 solver.cpp:214] Iteration 240, loss = 1.35545
I0418 18:39:55.989503 24121 solver.cpp:229]     Train net output #0: accuracy = 0.566854
I0418 18:39:55.989545 24121 solver.cpp:229]     Train net output #1: loss = 1.35545 (* 1 = 1.35545 loss)
I0418 18:39:55.989558 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.853437
I0418 18:39:55.989573 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = 0
I0418 18:39:55.989579 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:39:55.989584 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:39:55.989590 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:39:55.989595 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:39:55.989601 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 18:39:55.989606 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:39:55.989611 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:39:55.989617 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:39:55.989622 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:39:55.989629 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:39:55.989634 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 18:39:55.989639 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:39:55.989645 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = 0.000103699
I0418 18:39:55.989651 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = -nan
I0418 18:39:55.989657 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:39:55.989662 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:39:55.989667 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:39:55.989673 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:39:55.989678 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:39:55.989698 24121 solver.cpp:486] Iteration 240, lr = 0.001
I0418 18:41:50.804764 24121 solver.cpp:214] Iteration 260, loss = 0.530551
I0418 18:41:50.805013 24121 solver.cpp:229]     Train net output #0: accuracy = 0.788258
I0418 18:41:50.805053 24121 solver.cpp:229]     Train net output #1: loss = 0.530551 (* 1 = 0.530551 loss)
I0418 18:41:50.805063 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.885004
I0418 18:41:50.805069 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:41:50.805075 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:41:50.805080 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:41:50.805086 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:41:50.805091 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:41:50.805096 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 18:41:50.805102 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:41:50.805107 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:41:50.805112 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:41:50.805119 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:41:50.805124 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:41:50.805130 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 18:41:50.805135 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:41:50.805140 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:41:50.805145 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.113647
I0418 18:41:50.805151 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:41:50.805156 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:41:50.805162 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:41:50.805167 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = 0.000156723
I0418 18:41:50.805173 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = 0
I0418 18:41:50.805186 24121 solver.cpp:486] Iteration 260, lr = 0.001
I0418 18:43:44.968519 24121 solver.cpp:214] Iteration 280, loss = 2.24586
I0418 18:43:44.968719 24121 solver.cpp:229]     Train net output #0: accuracy = 0.525894
I0418 18:43:44.968740 24121 solver.cpp:229]     Train net output #1: loss = 2.24586 (* 1 = 2.24586 loss)
I0418 18:43:44.968747 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.936008
I0418 18:43:44.968755 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:43:44.968760 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:43:44.968765 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = 0
I0418 18:43:44.968771 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:43:44.968777 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:43:44.968782 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 18:43:44.968787 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:43:44.968793 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:43:44.968798 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = 0.000110096
I0418 18:43:44.968804 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:43:44.968812 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:43:44.968818 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = 0
I0418 18:43:44.968824 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:43:44.968830 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = 0
I0418 18:43:44.968837 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.0705441
I0418 18:43:44.968842 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:43:44.968847 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:43:44.968853 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:43:44.968858 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:43:44.968863 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:43:44.968875 24121 solver.cpp:486] Iteration 280, lr = 0.001
I0418 18:45:38.785815 24121 solver.cpp:214] Iteration 300, loss = 0.472202
I0418 18:45:38.786140 24121 solver.cpp:229]     Train net output #0: accuracy = 0.870838
I0418 18:45:38.786175 24121 solver.cpp:229]     Train net output #1: loss = 0.472202 (* 1 = 0.472202 loss)
I0418 18:45:38.786183 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.942831
I0418 18:45:38.786190 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:45:38.786196 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = 0
I0418 18:45:38.786202 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:45:38.786207 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:45:38.786213 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = 0
I0418 18:45:38.786219 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 18:45:38.786224 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:45:38.786229 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = 0
I0418 18:45:38.786242 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:45:38.786252 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:45:38.786263 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:45:38.786274 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 18:45:38.786285 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:45:38.786296 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:45:38.786306 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.0522876
I0418 18:45:38.786319 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = 0
I0418 18:45:38.786331 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:45:38.786342 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:45:38.786353 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:45:38.786365 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:45:38.786384 24121 solver.cpp:486] Iteration 300, lr = 0.001
I0418 18:47:33.617661 24121 solver.cpp:214] Iteration 320, loss = 0.862531
I0418 18:47:33.617877 24121 solver.cpp:229]     Train net output #0: accuracy = 0.682988
I0418 18:47:33.617902 24121 solver.cpp:229]     Train net output #1: loss = 0.86253 (* 1 = 0.86253 loss)
I0418 18:47:33.617913 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.928245
I0418 18:47:33.617920 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:47:33.617926 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:47:33.617931 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:47:33.617938 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:47:33.617943 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:47:33.617949 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = 0
I0418 18:47:33.617957 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:47:33.617964 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:47:33.617969 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:47:33.617974 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:47:33.617980 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:47:33.617985 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = 8.62069e-05
I0418 18:47:33.617991 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:47:33.617997 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:47:33.618002 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = -nan
I0418 18:47:33.618008 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:47:33.618013 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:47:33.618018 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:47:33.618024 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:47:33.618029 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:47:33.618041 24121 solver.cpp:486] Iteration 320, lr = 0.001
I0418 18:49:27.605907 24121 solver.cpp:214] Iteration 340, loss = 1.25662
I0418 18:49:27.606184 24121 solver.cpp:229]     Train net output #0: accuracy = 0.55292
I0418 18:49:27.606209 24121 solver.cpp:229]     Train net output #1: loss = 1.25662 (* 1 = 1.25662 loss)
I0418 18:49:27.606220 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.947366
I0418 18:49:27.606227 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:49:27.606233 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:49:27.606238 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:49:27.606243 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:49:27.606250 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:49:27.606254 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 18:49:27.606259 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:49:27.606266 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:49:27.606271 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:49:27.606276 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:49:27.606281 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:49:27.606287 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 18:49:27.606292 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:49:27.606297 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:49:27.606302 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.0524959
I0418 18:49:27.606308 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:49:27.606313 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:49:27.606318 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:49:27.606324 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:49:27.606329 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = 0
I0418 18:49:27.606341 24121 solver.cpp:486] Iteration 340, lr = 0.001
I0418 18:51:22.317531 24121 solver.cpp:214] Iteration 360, loss = 1.1824
I0418 18:51:22.317737 24121 solver.cpp:229]     Train net output #0: accuracy = 0.5488
I0418 18:51:22.317762 24121 solver.cpp:229]     Train net output #1: loss = 1.1824 (* 1 = 1.1824 loss)
I0418 18:51:22.317775 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.779508
I0418 18:51:22.317782 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:51:22.317788 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:51:22.317793 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:51:22.317798 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:51:22.317805 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:51:22.317809 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 18:51:22.317819 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:51:22.317826 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:51:22.317831 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:51:22.317836 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:51:22.317841 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:51:22.317847 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = 0
I0418 18:51:22.317852 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = 0
I0418 18:51:22.317858 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:51:22.317863 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = -nan
I0418 18:51:22.317868 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:51:22.317874 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:51:22.317879 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:51:22.317885 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:51:22.317890 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:51:22.317901 24121 solver.cpp:486] Iteration 360, lr = 0.001
I0418 18:53:16.695140 24121 solver.cpp:214] Iteration 380, loss = 0.797326
I0418 18:53:16.695416 24121 solver.cpp:229]     Train net output #0: accuracy = 0.677386
I0418 18:53:16.695456 24121 solver.cpp:229]     Train net output #1: loss = 0.797326 (* 1 = 0.797326 loss)
I0418 18:53:16.695464 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.840088
I0418 18:53:16.695472 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:53:16.695477 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:53:16.695483 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:53:16.695488 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:53:16.695493 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:53:16.695499 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 18:53:16.695510 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:53:16.695521 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:53:16.695533 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:53:16.695547 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:53:16.695576 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:53:16.695590 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 18:53:16.695601 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = 0
I0418 18:53:16.695616 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:53:16.695631 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.154062
I0418 18:53:16.695646 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:53:16.695659 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:53:16.695672 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:53:16.695688 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = 0
I0418 18:53:16.695704 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:53:16.695727 24121 solver.cpp:486] Iteration 380, lr = 0.001
I0418 18:55:10.977919 24121 solver.cpp:214] Iteration 400, loss = 0.649557
I0418 18:55:10.978162 24121 solver.cpp:229]     Train net output #0: accuracy = 0.65214
I0418 18:55:10.978210 24121 solver.cpp:229]     Train net output #1: loss = 0.649557 (* 1 = 0.649557 loss)
I0418 18:55:10.978230 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.818094
I0418 18:55:10.978245 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:55:10.978255 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:55:10.978284 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:55:10.978296 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:55:10.978308 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:55:10.978322 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 18:55:10.978334 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:55:10.978348 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = 0
I0418 18:55:10.978364 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:55:10.978379 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:55:10.978394 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:55:10.978409 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 18:55:10.978421 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:55:10.978435 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:55:10.978448 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.180286
I0418 18:55:10.978462 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:55:10.978476 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:55:10.978489 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:55:10.978502 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:55:10.978514 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:55:10.978538 24121 solver.cpp:486] Iteration 400, lr = 0.001
I0418 18:57:05.552351 24121 solver.cpp:214] Iteration 420, loss = 1.49708
I0418 18:57:05.552642 24121 solver.cpp:229]     Train net output #0: accuracy = 0.701194
I0418 18:57:05.552667 24121 solver.cpp:229]     Train net output #1: loss = 1.49708 (* 1 = 1.49708 loss)
I0418 18:57:05.552680 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.918339
I0418 18:57:05.552686 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:57:05.552692 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:57:05.552697 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = 0
I0418 18:57:05.552703 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 18:57:05.552709 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:57:05.552714 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 18:57:05.552721 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:57:05.552726 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:57:05.552733 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:57:05.552739 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:57:05.552745 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:57:05.552750 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 18:57:05.552757 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:57:05.552762 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:57:05.552767 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = -nan
I0418 18:57:05.552772 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:57:05.552778 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:57:05.552783 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:57:05.552788 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:57:05.552793 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = 0
I0418 18:57:05.552805 24121 solver.cpp:486] Iteration 420, lr = 0.001
I0418 18:59:00.006716 24121 solver.cpp:214] Iteration 440, loss = 0.342483
I0418 18:59:00.007027 24121 solver.cpp:229]     Train net output #0: accuracy = 0.831694
I0418 18:59:00.007051 24121 solver.cpp:229]     Train net output #1: loss = 0.342483 (* 1 = 0.342483 loss)
I0418 18:59:00.007061 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.894193
I0418 18:59:00.007066 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 18:59:00.007072 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 18:59:00.007078 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 18:59:00.007086 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = 0
I0418 18:59:00.007091 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 18:59:00.007097 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 18:59:00.007102 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 18:59:00.007113 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 18:59:00.007119 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 18:59:00.007124 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 18:59:00.007130 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 18:59:00.007135 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 18:59:00.007140 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 18:59:00.007146 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 18:59:00.007151 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.104131
I0418 18:59:00.007158 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 18:59:00.007164 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 18:59:00.007169 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 18:59:00.007174 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 18:59:00.007179 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 18:59:00.007191 24121 solver.cpp:486] Iteration 440, lr = 0.001
I0418 19:00:54.408608 24121 solver.cpp:214] Iteration 460, loss = 1.55337
I0418 19:00:54.408833 24121 solver.cpp:229]     Train net output #0: accuracy = 0.563964
I0418 19:00:54.408857 24121 solver.cpp:229]     Train net output #1: loss = 1.55337 (* 1 = 1.55337 loss)
I0418 19:00:54.408869 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.976385
I0418 19:00:54.408876 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 19:00:54.408882 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 19:00:54.408887 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 19:00:54.408893 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = 2.95438e-05
I0418 19:00:54.408900 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 19:00:54.408905 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = 0
I0418 19:00:54.408911 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = 0.000218938
I0418 19:00:54.408917 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 19:00:54.408923 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 19:00:54.408928 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 19:00:54.408933 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 19:00:54.408939 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 19:00:54.408944 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 19:00:54.408949 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 19:00:54.408956 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.0226115
I0418 19:00:54.408962 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 19:00:54.408967 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 19:00:54.408972 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 19:00:54.408977 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 19:00:54.408983 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 19:00:54.408994 24121 solver.cpp:486] Iteration 460, lr = 0.001
I0418 19:02:49.481178 24121 solver.cpp:214] Iteration 480, loss = 1.99005
I0418 19:02:49.481359 24121 solver.cpp:229]     Train net output #0: accuracy = 0.442432
I0418 19:02:49.481375 24121 solver.cpp:229]     Train net output #1: loss = 1.99005 (* 1 = 1.99005 loss)
I0418 19:02:49.481382 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.886644
I0418 19:02:49.481389 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 19:02:49.481395 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 19:02:49.481400 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 19:02:49.481405 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 19:02:49.481410 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 19:02:49.481416 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 19:02:49.481421 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 19:02:49.481426 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 19:02:49.481432 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 19:02:49.481437 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 19:02:49.481442 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 19:02:49.481448 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = 0
I0418 19:02:49.481453 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 19:02:49.481465 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 19:02:49.481477 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.111009
I0418 19:02:49.481489 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 19:02:49.481499 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 19:02:49.481533 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 19:02:49.481545 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 19:02:49.481556 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = 0.000282206
I0418 19:02:49.481595 24121 solver.cpp:486] Iteration 480, lr = 0.001
I0418 19:04:44.410444 24121 solver.cpp:214] Iteration 500, loss = 1.71759
I0418 19:04:44.410676 24121 solver.cpp:229]     Train net output #0: accuracy = 0.49571
I0418 19:04:44.410715 24121 solver.cpp:229]     Train net output #1: loss = 1.71759 (* 1 = 1.71759 loss)
I0418 19:04:44.410725 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.880973
I0418 19:04:44.410732 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 19:04:44.410738 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 19:04:44.410743 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 19:04:44.410749 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 19:04:44.410754 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 19:04:44.410760 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 19:04:44.410765 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = 0.00203324
I0418 19:04:44.410773 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 19:04:44.410778 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 19:04:44.410784 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 19:04:44.410792 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 19:04:44.410804 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 19:04:44.410815 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 19:04:44.410825 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 19:04:44.410837 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = -nan
I0418 19:04:44.410848 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 19:04:44.410858 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 19:04:44.410871 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 19:04:44.410881 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 19:04:44.410892 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 19:04:44.410912 24121 solver.cpp:486] Iteration 500, lr = 0.001
I0418 19:06:39.028800 24121 solver.cpp:214] Iteration 520, loss = 1.66418
I0418 19:06:39.029086 24121 solver.cpp:229]     Train net output #0: accuracy = 0.610024
I0418 19:06:39.029124 24121 solver.cpp:229]     Train net output #1: loss = 1.66418 (* 1 = 1.66418 loss)
I0418 19:06:39.029132 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.979259
I0418 19:06:39.029144 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = -nan
I0418 19:06:39.029155 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 19:06:39.029166 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 19:06:39.029178 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 19:06:39.029189 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = -nan
I0418 19:06:39.029201 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 19:06:39.029211 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 19:06:39.029222 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 19:06:39.029233 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = -nan
I0418 19:06:39.029244 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = 0
I0418 19:06:39.029256 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = -nan
I0418 19:06:39.029268 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 19:06:39.029278 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = 0
I0418 19:06:39.029290 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 19:06:39.029301 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.0158856
I0418 19:06:39.029314 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 19:06:39.029325 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 19:06:39.029336 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 19:06:39.029347 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 19:06:39.029358 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = -nan
I0418 19:06:39.029378 24121 solver.cpp:486] Iteration 520, lr = 0.001
I0418 19:08:33.773306 24121 solver.cpp:214] Iteration 540, loss = 1.96936
I0418 19:08:33.773525 24121 solver.cpp:229]     Train net output #0: accuracy = 0.588078
I0418 19:08:33.773542 24121 solver.cpp:229]     Train net output #1: loss = 1.96936 (* 1 = 1.96936 loss)
I0418 19:08:33.773550 24121 solver.cpp:229]     Train net output #2: per_class_accuracy = 0.997554
I0418 19:08:33.773556 24121 solver.cpp:229]     Train net output #3: per_class_accuracy = 4.10796e-05
I0418 19:08:33.773563 24121 solver.cpp:229]     Train net output #4: per_class_accuracy = -nan
I0418 19:08:33.773569 24121 solver.cpp:229]     Train net output #5: per_class_accuracy = -nan
I0418 19:08:33.773574 24121 solver.cpp:229]     Train net output #6: per_class_accuracy = -nan
I0418 19:08:33.773581 24121 solver.cpp:229]     Train net output #7: per_class_accuracy = 0
I0418 19:08:33.773586 24121 solver.cpp:229]     Train net output #8: per_class_accuracy = -nan
I0418 19:08:33.773591 24121 solver.cpp:229]     Train net output #9: per_class_accuracy = -nan
I0418 19:08:33.773597 24121 solver.cpp:229]     Train net output #10: per_class_accuracy = -nan
I0418 19:08:33.773602 24121 solver.cpp:229]     Train net output #11: per_class_accuracy = 0
I0418 19:08:33.773608 24121 solver.cpp:229]     Train net output #12: per_class_accuracy = -nan
I0418 19:08:33.773613 24121 solver.cpp:229]     Train net output #13: per_class_accuracy = 1.99255e-05
I0418 19:08:33.773620 24121 solver.cpp:229]     Train net output #14: per_class_accuracy = -nan
I0418 19:08:33.773625 24121 solver.cpp:229]     Train net output #15: per_class_accuracy = -nan
I0418 19:08:33.773630 24121 solver.cpp:229]     Train net output #16: per_class_accuracy = -nan
I0418 19:08:33.773638 24121 solver.cpp:229]     Train net output #17: per_class_accuracy = 0.000452694
I0418 19:08:33.773645 24121 solver.cpp:229]     Train net output #18: per_class_accuracy = -nan
I0418 19:08:33.773651 24121 solver.cpp:229]     Train net output #19: per_class_accuracy = -nan
I0418 19:08:33.773656 24121 solver.cpp:229]     Train net output #20: per_class_accuracy = -nan
I0418 19:08:33.773661 24121 solver.cpp:229]     Train net output #21: per_class_accuracy = -nan
I0418 19:08:33.773668 24121 solver.cpp:229]     Train net output #22: per_class_accuracy = 0.000300752
I0418 19:08:33.773679 24121 solver.cpp:486] Iteration 540, lr = 0.001
