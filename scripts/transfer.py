#!/usr/bin/env python

"""Carries out transfer learning according to a provided configuration file."""
# TODO: Use logging
# TODO: Also take in charge absolute paths
# TODO: Think about the preProcFun -> should be usable easily
# TODO: Test all asserts


# auto-generated python class for protobuf formats
import transferLearning_pb2
import argparse
import os
import warnings
import logging

FILENAME_FIELD = 'filename'
NET_FILENAME_FIELD = 'net_filename'
HALT_FIELD = 'halt_percentage'
INIT_STAGE_FIELD = 'init_stage'
INIT_WEIGHTS_FIELD = 'init_weights'
OUT_DIR_FIELD = 'out_dir'


def getArguments():
    """Defines and parses command-line arguments to this script."""
    parser = argparse.ArgumentParser()
    
    # optional arguments
    parser.add_argument('--weights', help='\
    A .caffemodel file containing the initial weights of the first stage. \
    Overrides init_weights specified in configuration file, if any. If not \
    provided, the first stage will learn all weights from scratch.')
    parser.add_argument('-o', '--out_dir', help='\
    A directory in which to store the output caffe models. Overrides out_dir \
    specified in configuration file, if any.')
    
    machineGroup = parser.add_mutually_exclusive_group()
    machineGroup.add_argument('--cpu', action='store_true', help='\
    If this flag is set, runs all training on the CPU.')
    machineGroup.add_argument('--gpu', type=int, default=0, help='\
    Allows the user to specify which GPU training will run on.')
    
    parser.add_argument('--clean', action="store_true", help='\
    Cleans up intermediate files as the script finishes with them.')
    parser.add_argument('--quiet', action='store_true', help='\
    Run in non-verbose mode.')
    parser.add_argument('--resume', help='\
    Use a snapshot file (generated by the framework but also modifiable) and \
    resume a training with it.')

    # required arguments
    parser.add_argument('config', help='\
    A .prototxt file defining the transfer learning stages to be performed.')
    return parser.parse_args()


def getStageFromMsg(stageMsg, configDir, outDir):
    # unpack values
    preProcFun = None
    if stageMsg.fcn_surgery:
        preProcFun = fcnSurgery.fcnInterp
    haltPercent = None
    if stageMsg.HasField(HALT_FIELD):
        haltPercent = stageMsg.halt_percentage
    
    # The solver_filename is relative to config file
    solverFilename = os.path.join(configDir, stageMsg.solver_filename)
    return stage.Stage(stageMsg.name, solverFilename, stageMsg.freeze,
                       stageMsg.ignore, preProcFun, haltPercent, outDir,
                       stageMsg.dataLayer, stageMsg.lossLayer,
                       stageMsg.outLayer, stageMsg.labelLayer)
    

def getStagesFromMsgs(multiSourceMsg, configDir, outDir):
    """Instantiates a sequence of stages from protobuf "stage" messages."""
    stages = [getStageFromMsg(stageMsg, configDir, outDir)
              for stageMsg in multiSourceMsg.stage]
    initStage = None
    if multiSourceMsg.HasField(INIT_STAGE_FIELD):
        initStage = getStageFromMsg(multiSourceMsg.init_stage, configDir, \
                                    outDir)
    return initStage, stages


def executeListOfStages(stages, firstModel, clean=False):
    model = firstModel
    allResults = []
    scores = None
    
    for s in stages:
        print '-> Execute stage', s.name
        newModel, scores = s.execute(model)
        if clean:
            # Delete each model as soon as we're finished with it
            if model != firstModel:
                os.remove(model)
        else:
            # Save the nextResults of each model
            allResults.append((newModel, scores))
        model = newModel
        print '-> Produce the model', model

    if clean:
        # Only the last was saved
        allResults = [(model, scores)]
    
    # Return the models produced. Warning, the shape is not the same depending
    # on the clean argument
    return allResults


def getScore(scores, scoreMetric):
    if scoreMetric == transferLearning_pb2.MultiSource.MEAN_IU:
        return scores.meanIu
    elif scoreMetric == transferLearning_pb2.MultiSource.ACCURACY:
        return scores.meanAcc
    elif scoreMetric == transferLearning_pb2.MultiSource.LOSS:
        return scores.loss
    else:
        raise Exception("An invalid scoreMetric was specified: " +
                        str(scoreMetric))
    

if __name__ == "__main__":
    args = getArguments()
    if args.quiet:
        os.environ['GLOG_minloglevel'] = '3'
        warnings.filterwarnings("ignore")
        logging.basicConfig(level=logging.INFO)
        # TODO: also deal with protobuf warnings
    
    # Must change log level prior to importing caffe
    import caffe
    from caffeUtils import protoUtils, fcnSurgery
    import stage

    # Set the caffe device
    if args.cpu:
        caffe.set_mode_cpu()
    else:
        # TODO: set_device(1) runs the framework on gpu 0
        caffe.set_device(args.gpu)
        caffe.set_mode_gpu()

    # Read in the configuration file
    tlMsg = transferLearning_pb2.TransferLearning()
    protoUtils.readFromPrototxt(tlMsg, args.config)
    configDir = os.path.dirname(args.config)
    
    # Command-line out dir takes priority
    outDir = args.out_dir
    if outDir is None and tlMsg.HasField(OUT_DIR_FIELD):
        # then config file out dir, relative to config file's location
        outDir = os.path.join(configDir, tlMsg.out_dir)
    print 'Will save all the results into', outDir

    # Command-line init weights take priority
    prevModel = args.weights
    if prevModel is None and tlMsg.HasField(INIT_WEIGHTS_FIELD):
        # then config file init weights, relative to config file's location
        prevModel = os.path.join(configDir, tlMsg.init_weights)
    print 'Will initialize with the weights :', prevModel
    
    # For each multiSource message in the config file
    for msMsg in tlMsg.multi_source:
        assert msMsg.iterations > 0, \
        ' '.join(["The number of iterations should be > 0. (current:", \
                  str(msMsg.iterations), ")"])
        
        # Get the stages from the current multisource message
        initStage, stages = getStagesFromMsgs(msMsg, configDir, outDir)
        
        # Paths to the best models saved and their scores
        bestModels = [None]
        bestScores = [float('-inf')]
        if not args.clean:
            # We will have to save the best models / scores for each stage
            bestModels = [None] * len(stages)
            bestScores = [float('-inf')] * len(stages)
        
        # For each iteration of this multiSource
        for j in range(msMsg.iterations):
            print "Starting multi-source iteration", j, "from", prevModel
            
            # Will store the models, scores generated by the list of stages
            # for this iteration
            nextResults = None
            
            # If we have to execute the init_stage
            if initStage is not None and j is 0:
                # On the first iteration, run initStage instead of first stage
                allStages = [initStage] + stages[1:]
                nextResults = executeListOfStages(allStages, prevModel,
                                                  args.clean)
            else:
                nextResults = executeListOfStages(stages, prevModel,
                                                  args.clean)
            
            # Get the results
            nextModels, nextScores = zip(*nextResults)
            
            # Checking the results
            assert (len(nextModels) == len(nextScores)) and \
                   ((args.clean and len(nextModels) == 1) or \
                    (not args.clean and len(nextModels) == len(stages))), \
            ' '.join(["nextModels and nextScores' shape mismatch.\n", \
                      "nb of elements in nextModels :", \
                            str(len(nextModels)), "\n", \
                      "nb of elements in nextScores :", \
                            str(len(nextScores)), "\n", \
                      "expected nb of elements :", \
                            str("1" if args.clean else len(stages))])
            
            # Check if these are the new best models for their stage
            for i in range(len(bestModels)):
                if nextScores[i] is None:
                    # No scores given, so just assume it's better
                    print 'New score is None, assume the new model is the best'
                    bestModels[i] = nextModels[i]
                else:
                    # Save each stage's model if it's better than the previous
                    iNextScore = getScore(nextScores[i], msMsg.score_metric)
                    if iNextScore > bestScores[i]:
                        bestModels[i] = nextModels[i]
                        bestScores[i] = iNextScore
                        print ' '.join(["New best score for stage",
                                        stages[i].name, ":", str(iNextScore)])
                    else:
                        print 'Previous score for', i, 'is better than the', \
                               'new one, so we just keep it.'
                        
            # Input model of the next iteration is the best last-stage model
            prevModel = nextModels[-1]
            
            # Delete any models that are no longer needed 
            for model in nextModels:
                notNeeded = model not in bestModels and model != prevModel
                if model is not None and notNeeded and args.clean:
                    os.remove(model)
    
    print 'Final models stored in', ', '.join(bestModels)
    raise SystemExit
    
